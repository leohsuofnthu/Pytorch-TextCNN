{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textCNN_IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leohsuofnthu/Pytorch-TextCNN/blob/master/textCNN_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDi2Zu6Wduss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from numpy.random import RandomState\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import Iterator, BucketIterator\n",
        "import torchtext.datasets\n",
        "from torchtext.datasets import IMDB, SST\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3b8tR4hUI1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Split whole dataset into train and valid set\n",
        "df = pd.read_csv('./quora.csv')\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df.sample(frac=0.8, random_state=rng)\n",
        "tst = df.loc[~df.index.isin(tr.index)]\n",
        "tr.to_csv('train.csv', index=False)\n",
        "tst.to_csv('test.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLibIFbDUmTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Prepare the dataset via torchtext\n",
        "spacy_en = spacy.load('en', disable=['tagger', 'parser', 'ner', 'textcat'\n",
        "                                     'entity_ruler', 'sentencizer', \n",
        "                                     'merge_noun_chunks', 'merge_entities',\n",
        "                                     'merge_subtokens'])\n",
        "\n",
        "def tokenizer(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "  \n",
        "# set up fields\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for all datasets except for SST.\n",
        "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip()\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "#Creating field for text and label\n",
        "REVIEW = Field(sequential=True, tokenize=tokenizer, lower=True)\n",
        "LABEL = Field(sequential=False, use_vocab=False)\n",
        "\n",
        "#clean the text\n",
        "REVIEW.preprocessing = torchtext.data.Pipeline(clean_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y53KC7iV0rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "train_datafield = [('qid',None), ('question_text', REVIEW),  ('target', LABEL)]\n",
        "train = TabularDataset(path ='./train.csv',  \n",
        "                             format='csv',\n",
        "                             skip_header=True,\n",
        "                             fields=train_datafield)\n",
        "\n",
        "\n",
        "#%%\n",
        "test_datafield = [('qid',None), ('question_text', REVIEW),  ('target',LABEL)]\n",
        "\n",
        "test = TabularDataset(path ='./test.csv', \n",
        "                       format='csv',\n",
        "                       skip_header=True,\n",
        "                       fields=test_datafield)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4hEm_F-uC8C",
        "colab_type": "code",
        "outputId": "efc2b8b1-cc1a-4d88-e191-55c42cb34233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#%%Show some example to show the dataset\n",
        "print(train[0].question_text,  train[0].target)\n",
        "print(test[0].question_text,  test[0].target)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'much', 'gay', 'people', 'recreate', 'themselves', 'with', 'the', 'help', 'of', 'bongacam', 'sites', 'to', 'watch', 'some', 'worthy', 'porn', 'clips', '\\\\?'] 0\n",
            "['why', 'does', 'velocity', 'affect', 'time', '\\\\?', 'does', 'velocity', 'affect', 'space', 'geometry', '\\\\?'] 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0pRfczV41t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Check the dataset\n",
        "REVIEW.build_vocab(train, vectors=GloVe(name=\"6B\", dim=300))\n",
        "#LABEL.build_vocab(train)\n",
        "#%% load the pretrained embedding\n",
        "vocab = REVIEW.vocab\n",
        "\n",
        "#%% Create the Iterator for datasets (Iterator works like dataloader)\n",
        "\n",
        "train_iter = Iterator(\n",
        "        train, \n",
        "        batch_size=64,\n",
        "        device=torch.device('cuda'), \n",
        "        sort_within_batch=False,\n",
        "        repeat=False)\n",
        "\n",
        "test_iter = Iterator(test, batch_size=64, device=torch.device('cuda'), \n",
        "                     sort_within_batch=False, repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSjRipJEYm5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Text CNN model\n",
        "class textCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "        super(textCNN, self).__init__()\n",
        "        #load pretrained embedding in embedding layer.\n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
        "    \n",
        "        #Convolutional Layers with different window size kernels\n",
        "#        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, w, emb_dim) for w in kernel_wins])\n",
        "        self.conv_w3 = nn.Conv2d(1, dim_channel, (3, emb_dim))\n",
        "        self.conv_w4 = nn.Conv2d(1, dim_channel, (4, emb_dim))\n",
        "        self.conv_w5 = nn.Conv2d(1, dim_channel, (5, emb_dim))\n",
        "    \n",
        "        #dropout layer\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        \n",
        "        #FC layer\n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x_3 = F.relu(self.conv_w3(x))\n",
        "        x_4 = F.relu(self.conv_w4(x))\n",
        "        x_5 = F.relu(self.conv_w5(x))\n",
        " \n",
        "        \n",
        "        x_3 = F.max_pool1d(x_3.squeeze(-1), x_3.size()[2])\n",
        "        x_4 = F.max_pool1d(x_4.squeeze(-1), x_4.size()[2])\n",
        "        x_5 = F.max_pool1d(x_5.squeeze(-1), x_5.size()[2])\n",
        "        \n",
        "        xx = torch.cat((x_3,x_4,x_5), dim=1)\n",
        "        xx = xx.squeeze(-1)\n",
        "        xx = self.dropout(xx)\n",
        "        logit = self.fc(xx)\n",
        "        return logit\n",
        "        \n",
        "\n",
        "#%% Training the Model\n",
        "def train(model, device, train_itr, optimizer, epoch, max_epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_itr:\n",
        "        text, target = batch.question_text, batch.target\n",
        "        text = torch.transpose(text,0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        logit = model(text)\n",
        "        \n",
        "        \n",
        "        loss = F.cross_entropy(logit, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss+= loss.item()\n",
        "        \n",
        "        return train_loss\n",
        "    \n",
        "def eval(model, device, data_iter):\n",
        "    model.eval()\n",
        "    corrects, avg_loss = 0,0\n",
        "    for batch in data_iter:\n",
        "        text, target = batch.question_text, batch.target\n",
        "        text = torch.transpose(text,0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        \n",
        "        avg_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "    \n",
        "    size = len(data_iter.dataset)\n",
        "    avg_loss /= size \n",
        "    accuracy = 100.0 * corrects/size\n",
        "    print('\\nEvaluation - loss: {:.6f} acc: {:.4f}%({}/{}) \\n'.format(avg_loss,accuracy,corrects,size))\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHg-VStdsrB",
        "colab_type": "code",
        "outputId": "a70d305c-acd2-46cd-868c-3cb81a86ed1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "#%%\n",
        "print(next(iter(train_iter)))\n",
        "\n",
        "model = textCNN(vocab, 300, 100, [6, 12 , 24] , 2).to('cuda')\n",
        "# print the model summery\n",
        "print(model)    \n",
        "    \n",
        "train_loss = []\n",
        "test_dicescore = []\n",
        "best_test_dicescore = -1\n",
        "\n",
        "# Use GPU if it is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 500+1):\n",
        "    #train loss\n",
        "    t_loss = train(model, device, train_iter, optimizer, epoch, 500)\n",
        "    print('Train Epoch: {} \\t Loss: {}'.format(epoch, t_loss))\n",
        "    \n",
        "    test_acc = eval(model, device, test_iter)\n",
        "    \n",
        "#    torch.cuda.empty_cache()\n",
        "#    print('current memory allocated: {}'.format(torch.cuda.memory_allocated() / 1024 ** 2))\n",
        "#    print('max memory allocated: {}'.format(torch.cuda.max_memory_allocated() / 1024 ** 2))\n",
        "#    print('cached memory: {}'.format(torch.cuda.memory_cached() / 1024 ** 2))\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-6728aa8bd587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print the model summery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-2c_6zMdwfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}