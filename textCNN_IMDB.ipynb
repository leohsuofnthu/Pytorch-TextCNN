{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textCNN_IMDB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leohsuofnthu/Pytorch-TextCNN/blob/master/textCNN_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDi2Zu6Wduss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from numpy.random import RandomState\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import Field\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.vocab import GloVe\n",
        "from torchtext.data import Iterator, BucketIterator\n",
        "import torchtext.datasets\n",
        "from torchtext.datasets import IMDB, SST\n",
        "\n",
        "import spacy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3b8tR4hUI1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Split whole dataset into train and valid set\n",
        "df = pd.read_csv('./IMDB Dataset.csv')\n",
        "rng = RandomState()\n",
        "\n",
        "tr = df.sample(frac=0.7, random_state=rng)\n",
        "tst = df.loc[~df.index.isin(tr.index)]\n",
        "tr.to_csv('train.csv', index=False)\n",
        "tst.to_csv('test.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLibIFbDUmTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Prepare the dataset via torchtext\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenizer(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "  \n",
        "# set up fields\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for all datasets except for SST.\n",
        "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip()\n",
        "  \n",
        "  \n",
        "\n",
        "\n",
        "#Creating field for text and label\n",
        "REVIEW = Field(sequential=True, tokenize=tokenizer, lower=True)\n",
        "LABEL = Field(sequential=False)\n",
        "\n",
        "#clean the text\n",
        "REVIEW.preprocessing = torchtext.data.Pipeline(clean_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y53KC7iV0rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "train_datafield = [('review', REVIEW),  ('sentiment', LABEL)]\n",
        "train = TabularDataset(path ='./train.csv',  \n",
        "                             format='csv',\n",
        "                             skip_header=True,\n",
        "                             fields=train_datafield)\n",
        "\n",
        "\n",
        "#%%\n",
        "test_datafield = [('review', REVIEW),  ('sentiment', LABEL)]\n",
        "\n",
        "test = TabularDataset(path ='./test.csv', \n",
        "                       format='csv',\n",
        "                       skip_header=True,\n",
        "                       fields=test_datafield)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0pRfczV41t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Check the dataset\n",
        "REVIEW.build_vocab(train, vectors=GloVe(name=\"6B\", dim=300))\n",
        "LABEL.build_vocab(train)\n",
        "#%% load the pretrained embedding\n",
        "vocab = REVIEW.vocab\n",
        "\n",
        "#%% Create the Iterator for datasets (Iterator works like dataloader)\n",
        "\n",
        "train_iter = Iterator(\n",
        "        train, \n",
        "        batch_size=64,\n",
        "        device=torch.device('cuda'), \n",
        "        sort_within_batch=False,\n",
        "        repeat=False)\n",
        "\n",
        "test_iter = Iterator(test, batch_size=64, device=torch.device('cuda'), \n",
        "                     sort_within_batch=False, repeat=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSjRipJEYm5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%% Text CNN model\n",
        "class textCNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_built, emb_dim, dim_channel, kernel_wins, num_class):\n",
        "        super(textCNN, self).__init__()\n",
        "        #load pretrained embedding in embedding layer.\n",
        "        self.embed = nn.Embedding(len(vocab_built), emb_dim)\n",
        "        self.embed.weight.data.copy_(vocab_built.vectors)\n",
        "    \n",
        "        #Convolutional Layers with different window size kernels\n",
        "#        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, w, emb_dim) for w in kernel_wins])\n",
        "        self.conv_w3 = nn.Conv2d(1, dim_channel, (3, emb_dim))\n",
        "        self.conv_w4 = nn.Conv2d(1, dim_channel, (4, emb_dim))\n",
        "        self.conv_w5 = nn.Conv2d(1, dim_channel, (5, emb_dim))\n",
        "    \n",
        "        #dropout layer\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        \n",
        "        #FC layer\n",
        "        self.fc = nn.Linear(len(kernel_wins)*dim_channel, num_class)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embed(x)\n",
        "        x = x.unsqueeze(1)\n",
        "        x_3 = F.relu(self.conv_w3(x))\n",
        "        x_4 = F.relu(self.conv_w4(x))\n",
        "        x_5 = F.relu(self.conv_w5(x))\n",
        " \n",
        "        \n",
        "        x_3 = F.max_pool1d(x_3.squeeze(-1), x_3.size()[2])\n",
        "        x_4 = F.max_pool1d(x_4.squeeze(-1), x_4.size()[2])\n",
        "        x_5 = F.max_pool1d(x_5.squeeze(-1), x_5.size()[2])\n",
        "        \n",
        "        xx = torch.cat((x_3,x_4,x_5), dim=1)\n",
        "        xx = xx.squeeze(-1)\n",
        "        xx = self.dropout(xx)\n",
        "        logit = self.fc(xx)\n",
        "        return logit\n",
        "        \n",
        "\n",
        "#%% Training the Model\n",
        "def train(model, device, train_itr, optimizer, epoch, max_epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_itr:\n",
        "        text, target = batch.review, batch.sentiment\n",
        "        text = torch.transpose(text,0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        logit = model(text)\n",
        "        \n",
        "        \n",
        "        loss = F.cross_entropy(logit, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss+= loss.item()\n",
        "        \n",
        "        return train_loss\n",
        "    \n",
        "def eval(model, device, data_iter):\n",
        "    model.eval()\n",
        "    corrects, avg_loss = 0,0\n",
        "    for batch in data_iter:\n",
        "        text, target = batch.review, batch.sentiment\n",
        "        text = torch.transpose(text,0, 1)\n",
        "        target.data.sub_(1)\n",
        "        text, target = text.to(device), target.to(device)\n",
        "        \n",
        "        logit = model(text)\n",
        "        loss = F.cross_entropy(logit, target)\n",
        "\n",
        "        \n",
        "        avg_loss += loss.item()\n",
        "        result = torch.max(logit,1)[1]\n",
        "        corrects += (result.view(target.size()).data == target.data).sum()\n",
        "    \n",
        "    size = len(data_iter.dataset)\n",
        "    avg_loss /= size \n",
        "    accuracy = 100.0 * corrects/size\n",
        "    print('\\nEvaluation - loss: {:.6f} acc: {:.4f}%({}/{}) \\n'.format(avg_loss,accuracy,corrects,size))\n",
        "    \n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNHg-VStdsrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6e5e033-ca07-4fb3-f00e-d11634f07d75"
      },
      "source": [
        "#%%\n",
        "print(next(iter(train_iter)))\n",
        "\n",
        "model = textCNN(vocab, 300, 100, [6, 12 , 24] , 2).to('cuda')\n",
        "# print the model summery\n",
        "print(model)    \n",
        "    \n",
        "train_loss = []\n",
        "test_dicescore = []\n",
        "best_test_dicescore = -1\n",
        "\n",
        "# Use GPU if it is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 500+1):\n",
        "    #train loss\n",
        "    t_loss = train(model, device, train_iter, optimizer, epoch, 500)\n",
        "    print('Train Epoch: {} \\t Loss: {}'.format(epoch, t_loss))\n",
        "    \n",
        "    test_acc = eval(model, device, test_iter)\n",
        "    \n",
        "#    torch.cuda.empty_cache()\n",
        "#    print('current memory allocated: {}'.format(torch.cuda.memory_allocated() / 1024 ** 2))\n",
        "#    print('max memory allocated: {}'.format(torch.cuda.max_memory_allocated() / 1024 ** 2))\n",
        "#    print('cached memory: {}'.format(torch.cuda.memory_cached() / 1024 ** 2))\n",
        "\n",
        "    \n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 64]\n",
            "\t[.review]:[torch.cuda.LongTensor of size 656x64 (GPU 0)]\n",
            "\t[.sentiment]:[torch.cuda.LongTensor of size 64 (GPU 0)]\n",
            "textCNN(\n",
            "  (embed): Embedding(111629, 300)\n",
            "  (conv_w3): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
            "  (conv_w4): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
            "  (conv_w5): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
            "  (dropout): Dropout(p=0.6)\n",
            "  (fc): Linear(in_features=300, out_features=2, bias=True)\n",
            ")\n",
            "Train Epoch: 1 \t Loss: 0.7648428678512573\n",
            "\n",
            "Evaluation - loss: 0.011033 acc: 49.0000%(7430/15000) \n",
            "\n",
            "Train Epoch: 2 \t Loss: 0.7414646148681641\n",
            "\n",
            "Evaluation - loss: 0.011097 acc: 49.0000%(7429/15000) \n",
            "\n",
            "Train Epoch: 3 \t Loss: 0.7350847125053406\n",
            "\n",
            "Evaluation - loss: 0.010740 acc: 57.0000%(8619/15000) \n",
            "\n",
            "Train Epoch: 4 \t Loss: 0.7557792663574219\n",
            "\n",
            "Evaluation - loss: 0.010891 acc: 50.0000%(7574/15000) \n",
            "\n",
            "Train Epoch: 5 \t Loss: 0.7046993970870972\n",
            "\n",
            "Evaluation - loss: 0.011524 acc: 50.0000%(7571/15000) \n",
            "\n",
            "Train Epoch: 6 \t Loss: 0.8107852935791016\n",
            "\n",
            "Evaluation - loss: 0.011295 acc: 50.0000%(7571/15000) \n",
            "\n",
            "Train Epoch: 7 \t Loss: 0.7749204039573669\n",
            "\n",
            "Evaluation - loss: 0.010726 acc: 50.0000%(7641/15000) \n",
            "\n",
            "Train Epoch: 8 \t Loss: 0.6740071177482605\n",
            "\n",
            "Evaluation - loss: 0.010544 acc: 64.0000%(9691/15000) \n",
            "\n",
            "Train Epoch: 9 \t Loss: 0.7030929327011108\n",
            "\n",
            "Evaluation - loss: 0.010594 acc: 54.0000%(8149/15000) \n",
            "\n",
            "Train Epoch: 10 \t Loss: 0.6915069222450256\n",
            "\n",
            "Evaluation - loss: 0.010662 acc: 50.0000%(7635/15000) \n",
            "\n",
            "Train Epoch: 11 \t Loss: 0.6809541583061218\n",
            "\n",
            "Evaluation - loss: 0.010582 acc: 52.0000%(7857/15000) \n",
            "\n",
            "Train Epoch: 12 \t Loss: 0.7058329582214355\n",
            "\n",
            "Evaluation - loss: 0.010480 acc: 56.0000%(8441/15000) \n",
            "\n",
            "Train Epoch: 13 \t Loss: 0.6719359159469604\n",
            "\n",
            "Evaluation - loss: 0.010376 acc: 62.0000%(9376/15000) \n",
            "\n",
            "Train Epoch: 14 \t Loss: 0.6986619234085083\n",
            "\n",
            "Evaluation - loss: 0.010301 acc: 66.0000%(10019/15000) \n",
            "\n",
            "Train Epoch: 15 \t Loss: 0.6380918622016907\n",
            "\n",
            "Evaluation - loss: 0.010327 acc: 60.0000%(9074/15000) \n",
            "\n",
            "Train Epoch: 16 \t Loss: 0.716407835483551\n",
            "\n",
            "Evaluation - loss: 0.010325 acc: 58.0000%(8770/15000) \n",
            "\n",
            "Train Epoch: 17 \t Loss: 0.6774972081184387\n",
            "\n",
            "Evaluation - loss: 0.010262 acc: 60.0000%(9058/15000) \n",
            "\n",
            "Train Epoch: 18 \t Loss: 0.6440443396568298\n",
            "\n",
            "Evaluation - loss: 0.010116 acc: 69.0000%(10376/15000) \n",
            "\n",
            "Train Epoch: 19 \t Loss: 0.5961585640907288\n",
            "\n",
            "Evaluation - loss: 0.010046 acc: 71.0000%(10750/15000) \n",
            "\n",
            "Train Epoch: 20 \t Loss: 0.7014500498771667\n",
            "\n",
            "Evaluation - loss: 0.010025 acc: 68.0000%(10322/15000) \n",
            "\n",
            "Train Epoch: 21 \t Loss: 0.6469743847846985\n",
            "\n",
            "Evaluation - loss: 0.009983 acc: 68.0000%(10308/15000) \n",
            "\n",
            "Train Epoch: 22 \t Loss: 0.7056013345718384\n",
            "\n",
            "Evaluation - loss: 0.009949 acc: 68.0000%(10242/15000) \n",
            "\n",
            "Train Epoch: 23 \t Loss: 0.6555008292198181\n",
            "\n",
            "Evaluation - loss: 0.009877 acc: 70.0000%(10607/15000) \n",
            "\n",
            "Train Epoch: 24 \t Loss: 0.6403272747993469\n",
            "\n",
            "Evaluation - loss: 0.009821 acc: 71.0000%(10790/15000) \n",
            "\n",
            "Train Epoch: 25 \t Loss: 0.7149381041526794\n",
            "\n",
            "Evaluation - loss: 0.009759 acc: 73.0000%(11050/15000) \n",
            "\n",
            "Train Epoch: 26 \t Loss: 0.6134210228919983\n",
            "\n",
            "Evaluation - loss: 0.009708 acc: 73.0000%(11083/15000) \n",
            "\n",
            "Train Epoch: 27 \t Loss: 0.6918294429779053\n",
            "\n",
            "Evaluation - loss: 0.009703 acc: 71.0000%(10668/15000) \n",
            "\n",
            "Train Epoch: 28 \t Loss: 0.6343298554420471\n",
            "\n",
            "Evaluation - loss: 0.009639 acc: 72.0000%(10830/15000) \n",
            "\n",
            "Train Epoch: 29 \t Loss: 0.6613149046897888\n",
            "\n",
            "Evaluation - loss: 0.009560 acc: 74.0000%(11169/15000) \n",
            "\n",
            "Train Epoch: 30 \t Loss: 0.6339693069458008\n",
            "\n",
            "Evaluation - loss: 0.009495 acc: 75.0000%(11357/15000) \n",
            "\n",
            "Train Epoch: 31 \t Loss: 0.5995915532112122\n",
            "\n",
            "Evaluation - loss: 0.009441 acc: 75.0000%(11337/15000) \n",
            "\n",
            "Train Epoch: 32 \t Loss: 0.6460824608802795\n",
            "\n",
            "Evaluation - loss: 0.009406 acc: 74.0000%(11153/15000) \n",
            "\n",
            "Train Epoch: 33 \t Loss: 0.6677528619766235\n",
            "\n",
            "Evaluation - loss: 0.009396 acc: 72.0000%(10892/15000) \n",
            "\n",
            "Train Epoch: 34 \t Loss: 0.595802366733551\n",
            "\n",
            "Evaluation - loss: 0.009447 acc: 68.0000%(10325/15000) \n",
            "\n",
            "Train Epoch: 35 \t Loss: 0.6660540103912354\n",
            "\n",
            "Evaluation - loss: 0.009466 acc: 66.0000%(10018/15000) \n",
            "\n",
            "Train Epoch: 36 \t Loss: 0.5600327253341675\n",
            "\n",
            "Evaluation - loss: 0.009440 acc: 66.0000%(9989/15000) \n",
            "\n",
            "Train Epoch: 37 \t Loss: 0.6972891688346863\n",
            "\n",
            "Evaluation - loss: 0.009232 acc: 71.0000%(10770/15000) \n",
            "\n",
            "Train Epoch: 38 \t Loss: 0.6192218065261841\n",
            "\n",
            "Evaluation - loss: 0.009072 acc: 76.0000%(11423/15000) \n",
            "\n",
            "Train Epoch: 39 \t Loss: 0.6740726232528687\n",
            "\n",
            "Evaluation - loss: 0.008974 acc: 78.0000%(11756/15000) \n",
            "\n",
            "Train Epoch: 40 \t Loss: 0.5694910287857056\n",
            "\n",
            "Evaluation - loss: 0.008923 acc: 78.0000%(11796/15000) \n",
            "\n",
            "Train Epoch: 41 \t Loss: 0.5425366759300232\n",
            "\n",
            "Evaluation - loss: 0.008875 acc: 78.0000%(11752/15000) \n",
            "\n",
            "Train Epoch: 42 \t Loss: 0.6227030754089355\n",
            "\n",
            "Evaluation - loss: 0.008838 acc: 77.0000%(11631/15000) \n",
            "\n",
            "Train Epoch: 43 \t Loss: 0.5630273818969727\n",
            "\n",
            "Evaluation - loss: 0.008886 acc: 74.0000%(11109/15000) \n",
            "\n",
            "Train Epoch: 44 \t Loss: 0.6314989328384399\n",
            "\n",
            "Evaluation - loss: 0.008870 acc: 73.0000%(10987/15000) \n",
            "\n",
            "Train Epoch: 45 \t Loss: 0.6103528141975403\n",
            "\n",
            "Evaluation - loss: 0.008730 acc: 75.0000%(11375/15000) \n",
            "\n",
            "Train Epoch: 46 \t Loss: 0.5913547873497009\n",
            "\n",
            "Evaluation - loss: 0.008621 acc: 77.0000%(11672/15000) \n",
            "\n",
            "Train Epoch: 47 \t Loss: 0.49743908643722534\n",
            "\n",
            "Evaluation - loss: 0.008512 acc: 79.0000%(11888/15000) \n",
            "\n",
            "Train Epoch: 48 \t Loss: 0.6181864738464355\n",
            "\n",
            "Evaluation - loss: 0.008437 acc: 80.0000%(12029/15000) \n",
            "\n",
            "Train Epoch: 49 \t Loss: 0.6356499195098877\n",
            "\n",
            "Evaluation - loss: 0.008403 acc: 79.0000%(11927/15000) \n",
            "\n",
            "Train Epoch: 50 \t Loss: 0.5734623074531555\n",
            "\n",
            "Evaluation - loss: 0.008365 acc: 79.0000%(11870/15000) \n",
            "\n",
            "Train Epoch: 51 \t Loss: 0.601067841053009\n",
            "\n",
            "Evaluation - loss: 0.008334 acc: 78.0000%(11826/15000) \n",
            "\n",
            "Train Epoch: 52 \t Loss: 0.4123245179653168\n",
            "\n",
            "Evaluation - loss: 0.008299 acc: 78.0000%(11742/15000) \n",
            "\n",
            "Train Epoch: 53 \t Loss: 0.58735591173172\n",
            "\n",
            "Evaluation - loss: 0.008221 acc: 78.0000%(11831/15000) \n",
            "\n",
            "Train Epoch: 54 \t Loss: 0.5555855631828308\n",
            "\n",
            "Evaluation - loss: 0.008107 acc: 79.0000%(11951/15000) \n",
            "\n",
            "Train Epoch: 55 \t Loss: 0.5077046155929565\n",
            "\n",
            "Evaluation - loss: 0.007974 acc: 81.0000%(12162/15000) \n",
            "\n",
            "Train Epoch: 56 \t Loss: 0.4832027554512024\n",
            "\n",
            "Evaluation - loss: 0.007899 acc: 81.0000%(12179/15000) \n",
            "\n",
            "Train Epoch: 57 \t Loss: 0.5109280347824097\n",
            "\n",
            "Evaluation - loss: 0.007887 acc: 80.0000%(12081/15000) \n",
            "\n",
            "Train Epoch: 58 \t Loss: 0.5211228132247925\n",
            "\n",
            "Evaluation - loss: 0.007866 acc: 79.0000%(11991/15000) \n",
            "\n",
            "Train Epoch: 59 \t Loss: 0.5746924877166748\n",
            "\n",
            "Evaluation - loss: 0.007806 acc: 79.0000%(11996/15000) \n",
            "\n",
            "Train Epoch: 60 \t Loss: 0.5176723003387451\n",
            "\n",
            "Evaluation - loss: 0.007675 acc: 81.0000%(12174/15000) \n",
            "\n",
            "Train Epoch: 61 \t Loss: 0.5166768431663513\n",
            "\n",
            "Evaluation - loss: 0.007554 acc: 81.0000%(12261/15000) \n",
            "\n",
            "Train Epoch: 62 \t Loss: 0.518315851688385\n",
            "\n",
            "Evaluation - loss: 0.007589 acc: 80.0000%(12014/15000) \n",
            "\n",
            "Train Epoch: 63 \t Loss: 0.51491379737854\n",
            "\n",
            "Evaluation - loss: 0.007690 acc: 77.0000%(11673/15000) \n",
            "\n",
            "Train Epoch: 64 \t Loss: 0.46416571736335754\n",
            "\n",
            "Evaluation - loss: 0.007694 acc: 77.0000%(11592/15000) \n",
            "\n",
            "Train Epoch: 65 \t Loss: 0.47089213132858276\n",
            "\n",
            "Evaluation - loss: 0.007641 acc: 77.0000%(11597/15000) \n",
            "\n",
            "Train Epoch: 66 \t Loss: 0.4918918013572693\n",
            "\n",
            "Evaluation - loss: 0.007471 acc: 78.0000%(11836/15000) \n",
            "\n",
            "Train Epoch: 67 \t Loss: 0.5046579837799072\n",
            "\n",
            "Evaluation - loss: 0.007288 acc: 80.0000%(12131/15000) \n",
            "\n",
            "Train Epoch: 68 \t Loss: 0.5621724128723145\n",
            "\n",
            "Evaluation - loss: 0.007133 acc: 82.0000%(12367/15000) \n",
            "\n",
            "Train Epoch: 69 \t Loss: 0.5162346363067627\n",
            "\n",
            "Evaluation - loss: 0.007117 acc: 82.0000%(12312/15000) \n",
            "\n",
            "Train Epoch: 70 \t Loss: 0.5264936685562134\n",
            "\n",
            "Evaluation - loss: 0.007197 acc: 81.0000%(12152/15000) \n",
            "\n",
            "Train Epoch: 71 \t Loss: 0.5078526735305786\n",
            "\n",
            "Evaluation - loss: 0.007373 acc: 79.0000%(11899/15000) \n",
            "\n",
            "Train Epoch: 72 \t Loss: 0.5138655304908752\n",
            "\n",
            "Evaluation - loss: 0.007431 acc: 78.0000%(11790/15000) \n",
            "\n",
            "Train Epoch: 73 \t Loss: 0.548052191734314\n",
            "\n",
            "Evaluation - loss: 0.007239 acc: 79.0000%(11995/15000) \n",
            "\n",
            "Train Epoch: 74 \t Loss: 0.4926773011684418\n",
            "\n",
            "Evaluation - loss: 0.007068 acc: 81.0000%(12165/15000) \n",
            "\n",
            "Train Epoch: 75 \t Loss: 0.44124162197113037\n",
            "\n",
            "Evaluation - loss: 0.006917 acc: 81.0000%(12291/15000) \n",
            "\n",
            "Train Epoch: 76 \t Loss: 0.47170671820640564\n",
            "\n",
            "Evaluation - loss: 0.006778 acc: 82.0000%(12388/15000) \n",
            "\n",
            "Train Epoch: 77 \t Loss: 0.49175459146499634\n",
            "\n",
            "Evaluation - loss: 0.006782 acc: 81.0000%(12283/15000) \n",
            "\n",
            "Train Epoch: 78 \t Loss: 0.40026000142097473\n",
            "\n",
            "Evaluation - loss: 0.006976 acc: 79.0000%(11988/15000) \n",
            "\n",
            "Train Epoch: 79 \t Loss: 0.4974420666694641\n",
            "\n",
            "Evaluation - loss: 0.007017 acc: 79.0000%(11877/15000) \n",
            "\n",
            "Train Epoch: 80 \t Loss: 0.430056095123291\n",
            "\n",
            "Evaluation - loss: 0.006845 acc: 80.0000%(12086/15000) \n",
            "\n",
            "Train Epoch: 81 \t Loss: 0.4493388533592224\n",
            "\n",
            "Evaluation - loss: 0.006584 acc: 82.0000%(12335/15000) \n",
            "\n",
            "Train Epoch: 82 \t Loss: 0.5164205431938171\n",
            "\n",
            "Evaluation - loss: 0.006530 acc: 82.0000%(12428/15000) \n",
            "\n",
            "Train Epoch: 83 \t Loss: 0.5572994351387024\n",
            "\n",
            "Evaluation - loss: 0.006529 acc: 82.0000%(12411/15000) \n",
            "\n",
            "Train Epoch: 84 \t Loss: 0.4195321202278137\n",
            "\n",
            "Evaluation - loss: 0.006476 acc: 82.0000%(12429/15000) \n",
            "\n",
            "Train Epoch: 85 \t Loss: 0.5012463331222534\n",
            "\n",
            "Evaluation - loss: 0.006431 acc: 82.0000%(12436/15000) \n",
            "\n",
            "Train Epoch: 86 \t Loss: 0.48550957441329956\n",
            "\n",
            "Evaluation - loss: 0.006356 acc: 82.0000%(12449/15000) \n",
            "\n",
            "Train Epoch: 87 \t Loss: 0.6310957670211792\n",
            "\n",
            "Evaluation - loss: 0.006359 acc: 82.0000%(12400/15000) \n",
            "\n",
            "Train Epoch: 88 \t Loss: 0.44059115648269653\n",
            "\n",
            "Evaluation - loss: 0.006415 acc: 82.0000%(12336/15000) \n",
            "\n",
            "Train Epoch: 89 \t Loss: 0.4749748110771179\n",
            "\n",
            "Evaluation - loss: 0.006333 acc: 82.0000%(12382/15000) \n",
            "\n",
            "Train Epoch: 90 \t Loss: 0.43617308139801025\n",
            "\n",
            "Evaluation - loss: 0.006291 acc: 82.0000%(12423/15000) \n",
            "\n",
            "Train Epoch: 91 \t Loss: 0.4354513883590698\n",
            "\n",
            "Evaluation - loss: 0.006236 acc: 82.0000%(12445/15000) \n",
            "\n",
            "Train Epoch: 92 \t Loss: 0.4711245000362396\n",
            "\n",
            "Evaluation - loss: 0.006182 acc: 83.0000%(12490/15000) \n",
            "\n",
            "Train Epoch: 93 \t Loss: 0.42070451378822327\n",
            "\n",
            "Evaluation - loss: 0.006165 acc: 83.0000%(12513/15000) \n",
            "\n",
            "Train Epoch: 94 \t Loss: 0.5511519312858582\n",
            "\n",
            "Evaluation - loss: 0.006183 acc: 83.0000%(12502/15000) \n",
            "\n",
            "Train Epoch: 95 \t Loss: 0.3307330012321472\n",
            "\n",
            "Evaluation - loss: 0.006204 acc: 83.0000%(12507/15000) \n",
            "\n",
            "Train Epoch: 96 \t Loss: 0.4430905878543854\n",
            "\n",
            "Evaluation - loss: 0.006385 acc: 82.0000%(12344/15000) \n",
            "\n",
            "Train Epoch: 97 \t Loss: 0.4252597391605377\n",
            "\n",
            "Evaluation - loss: 0.006349 acc: 82.0000%(12354/15000) \n",
            "\n",
            "Train Epoch: 98 \t Loss: 0.41868460178375244\n",
            "\n",
            "Evaluation - loss: 0.006166 acc: 83.0000%(12513/15000) \n",
            "\n",
            "Train Epoch: 99 \t Loss: 0.5015906691551208\n",
            "\n",
            "Evaluation - loss: 0.006035 acc: 83.0000%(12561/15000) \n",
            "\n",
            "Train Epoch: 100 \t Loss: 0.38416701555252075\n",
            "\n",
            "Evaluation - loss: 0.005989 acc: 83.0000%(12561/15000) \n",
            "\n",
            "Train Epoch: 101 \t Loss: 0.3858906328678131\n",
            "\n",
            "Evaluation - loss: 0.005963 acc: 83.0000%(12561/15000) \n",
            "\n",
            "Train Epoch: 102 \t Loss: 0.36593252420425415\n",
            "\n",
            "Evaluation - loss: 0.005966 acc: 83.0000%(12513/15000) \n",
            "\n",
            "Train Epoch: 103 \t Loss: 0.5091019868850708\n",
            "\n",
            "Evaluation - loss: 0.005963 acc: 83.0000%(12516/15000) \n",
            "\n",
            "Train Epoch: 104 \t Loss: 0.48852959275245667\n",
            "\n",
            "Evaluation - loss: 0.005943 acc: 83.0000%(12521/15000) \n",
            "\n",
            "Train Epoch: 105 \t Loss: 0.3203602433204651\n",
            "\n",
            "Evaluation - loss: 0.005928 acc: 83.0000%(12522/15000) \n",
            "\n",
            "Train Epoch: 106 \t Loss: 0.41919341683387756\n",
            "\n",
            "Evaluation - loss: 0.005903 acc: 83.0000%(12545/15000) \n",
            "\n",
            "Train Epoch: 107 \t Loss: 0.3689059317111969\n",
            "\n",
            "Evaluation - loss: 0.005865 acc: 83.0000%(12553/15000) \n",
            "\n",
            "Train Epoch: 108 \t Loss: 0.38891953229904175\n",
            "\n",
            "Evaluation - loss: 0.005836 acc: 83.0000%(12575/15000) \n",
            "\n",
            "Train Epoch: 109 \t Loss: 0.5297951698303223\n",
            "\n",
            "Evaluation - loss: 0.005800 acc: 84.0000%(12630/15000) \n",
            "\n",
            "Train Epoch: 110 \t Loss: 0.3916849195957184\n",
            "\n",
            "Evaluation - loss: 0.005791 acc: 84.0000%(12645/15000) \n",
            "\n",
            "Train Epoch: 111 \t Loss: 0.4011651873588562\n",
            "\n",
            "Evaluation - loss: 0.005872 acc: 84.0000%(12616/15000) \n",
            "\n",
            "Train Epoch: 112 \t Loss: 0.44384872913360596\n",
            "\n",
            "Evaluation - loss: 0.005953 acc: 83.0000%(12562/15000) \n",
            "\n",
            "Train Epoch: 113 \t Loss: 0.4681418836116791\n",
            "\n",
            "Evaluation - loss: 0.006041 acc: 83.0000%(12472/15000) \n",
            "\n",
            "Train Epoch: 114 \t Loss: 0.47588256001472473\n",
            "\n",
            "Evaluation - loss: 0.006020 acc: 83.0000%(12483/15000) \n",
            "\n",
            "Train Epoch: 115 \t Loss: 0.44210517406463623\n",
            "\n",
            "Evaluation - loss: 0.005897 acc: 83.0000%(12582/15000) \n",
            "\n",
            "Train Epoch: 116 \t Loss: 0.32799413800239563\n",
            "\n",
            "Evaluation - loss: 0.005771 acc: 84.0000%(12672/15000) \n",
            "\n",
            "Train Epoch: 117 \t Loss: 0.5730142593383789\n",
            "\n",
            "Evaluation - loss: 0.005693 acc: 84.0000%(12683/15000) \n",
            "\n",
            "Train Epoch: 118 \t Loss: 0.4280802011489868\n",
            "\n",
            "Evaluation - loss: 0.005681 acc: 84.0000%(12655/15000) \n",
            "\n",
            "Train Epoch: 119 \t Loss: 0.4316521883010864\n",
            "\n",
            "Evaluation - loss: 0.005668 acc: 84.0000%(12679/15000) \n",
            "\n",
            "Train Epoch: 120 \t Loss: 0.45910704135894775\n",
            "\n",
            "Evaluation - loss: 0.005693 acc: 84.0000%(12633/15000) \n",
            "\n",
            "Train Epoch: 121 \t Loss: 0.47032368183135986\n",
            "\n",
            "Evaluation - loss: 0.005693 acc: 84.0000%(12634/15000) \n",
            "\n",
            "Train Epoch: 122 \t Loss: 0.5260074138641357\n",
            "\n",
            "Evaluation - loss: 0.005632 acc: 84.0000%(12707/15000) \n",
            "\n",
            "Train Epoch: 123 \t Loss: 0.3221873939037323\n",
            "\n",
            "Evaluation - loss: 0.005630 acc: 84.0000%(12743/15000) \n",
            "\n",
            "Train Epoch: 124 \t Loss: 0.38772347569465637\n",
            "\n",
            "Evaluation - loss: 0.005715 acc: 84.0000%(12672/15000) \n",
            "\n",
            "Train Epoch: 125 \t Loss: 0.3770396411418915\n",
            "\n",
            "Evaluation - loss: 0.005837 acc: 83.0000%(12581/15000) \n",
            "\n",
            "Train Epoch: 126 \t Loss: 0.3221692740917206\n",
            "\n",
            "Evaluation - loss: 0.005832 acc: 83.0000%(12584/15000) \n",
            "\n",
            "Train Epoch: 127 \t Loss: 0.474825382232666\n",
            "\n",
            "Evaluation - loss: 0.005781 acc: 84.0000%(12623/15000) \n",
            "\n",
            "Train Epoch: 128 \t Loss: 0.49754753708839417\n",
            "\n",
            "Evaluation - loss: 0.005588 acc: 85.0000%(12761/15000) \n",
            "\n",
            "Train Epoch: 129 \t Loss: 0.3594241142272949\n",
            "\n",
            "Evaluation - loss: 0.005533 acc: 85.0000%(12762/15000) \n",
            "\n",
            "Train Epoch: 130 \t Loss: 0.35271039605140686\n",
            "\n",
            "Evaluation - loss: 0.005571 acc: 84.0000%(12741/15000) \n",
            "\n",
            "Train Epoch: 131 \t Loss: 0.29925981163978577\n",
            "\n",
            "Evaluation - loss: 0.005629 acc: 84.0000%(12672/15000) \n",
            "\n",
            "Train Epoch: 132 \t Loss: 0.4240305423736572\n",
            "\n",
            "Evaluation - loss: 0.005609 acc: 84.0000%(12676/15000) \n",
            "\n",
            "Train Epoch: 133 \t Loss: 0.5445334911346436\n",
            "\n",
            "Evaluation - loss: 0.005538 acc: 85.0000%(12750/15000) \n",
            "\n",
            "Train Epoch: 134 \t Loss: 0.32643675804138184\n",
            "\n",
            "Evaluation - loss: 0.005521 acc: 85.0000%(12768/15000) \n",
            "\n",
            "Train Epoch: 135 \t Loss: 0.34610068798065186\n",
            "\n",
            "Evaluation - loss: 0.005507 acc: 85.0000%(12774/15000) \n",
            "\n",
            "Train Epoch: 136 \t Loss: 0.41812747716903687\n",
            "\n",
            "Evaluation - loss: 0.005474 acc: 85.0000%(12795/15000) \n",
            "\n",
            "Train Epoch: 137 \t Loss: 0.3906857371330261\n",
            "\n",
            "Evaluation - loss: 0.005455 acc: 85.0000%(12791/15000) \n",
            "\n",
            "Train Epoch: 138 \t Loss: 0.4633384644985199\n",
            "\n",
            "Evaluation - loss: 0.005446 acc: 85.0000%(12817/15000) \n",
            "\n",
            "Train Epoch: 139 \t Loss: 0.3616239130496979\n",
            "\n",
            "Evaluation - loss: 0.005469 acc: 85.0000%(12815/15000) \n",
            "\n",
            "Train Epoch: 140 \t Loss: 0.3799320161342621\n",
            "\n",
            "Evaluation - loss: 0.005487 acc: 85.0000%(12801/15000) \n",
            "\n",
            "Train Epoch: 141 \t Loss: 0.3301977813243866\n",
            "\n",
            "Evaluation - loss: 0.005555 acc: 85.0000%(12753/15000) \n",
            "\n",
            "Train Epoch: 142 \t Loss: 0.4562395215034485\n",
            "\n",
            "Evaluation - loss: 0.005555 acc: 85.0000%(12759/15000) \n",
            "\n",
            "Train Epoch: 143 \t Loss: 0.4825700521469116\n",
            "\n",
            "Evaluation - loss: 0.005428 acc: 85.0000%(12825/15000) \n",
            "\n",
            "Train Epoch: 144 \t Loss: 0.363817423582077\n",
            "\n",
            "Evaluation - loss: 0.005378 acc: 85.0000%(12828/15000) \n",
            "\n",
            "Train Epoch: 145 \t Loss: 0.3707399070262909\n",
            "\n",
            "Evaluation - loss: 0.005402 acc: 85.0000%(12807/15000) \n",
            "\n",
            "Train Epoch: 146 \t Loss: 0.3113348186016083\n",
            "\n",
            "Evaluation - loss: 0.005471 acc: 84.0000%(12736/15000) \n",
            "\n",
            "Train Epoch: 147 \t Loss: 0.31926554441452026\n",
            "\n",
            "Evaluation - loss: 0.005590 acc: 84.0000%(12626/15000) \n",
            "\n",
            "Train Epoch: 148 \t Loss: 0.4504876732826233\n",
            "\n",
            "Evaluation - loss: 0.005503 acc: 84.0000%(12713/15000) \n",
            "\n",
            "Train Epoch: 149 \t Loss: 0.32802653312683105\n",
            "\n",
            "Evaluation - loss: 0.005439 acc: 84.0000%(12748/15000) \n",
            "\n",
            "Train Epoch: 150 \t Loss: 0.44510379433631897\n",
            "\n",
            "Evaluation - loss: 0.005387 acc: 85.0000%(12784/15000) \n",
            "\n",
            "Train Epoch: 151 \t Loss: 0.3589290380477905\n",
            "\n",
            "Evaluation - loss: 0.005345 acc: 85.0000%(12818/15000) \n",
            "\n",
            "Train Epoch: 152 \t Loss: 0.3590737283229828\n",
            "\n",
            "Evaluation - loss: 0.005315 acc: 85.0000%(12839/15000) \n",
            "\n",
            "Train Epoch: 153 \t Loss: 0.3017319440841675\n",
            "\n",
            "Evaluation - loss: 0.005291 acc: 85.0000%(12843/15000) \n",
            "\n",
            "Train Epoch: 154 \t Loss: 0.3192467987537384\n",
            "\n",
            "Evaluation - loss: 0.005270 acc: 85.0000%(12852/15000) \n",
            "\n",
            "Train Epoch: 155 \t Loss: 0.32947051525115967\n",
            "\n",
            "Evaluation - loss: 0.005262 acc: 85.0000%(12857/15000) \n",
            "\n",
            "Train Epoch: 156 \t Loss: 0.3924010694026947\n",
            "\n",
            "Evaluation - loss: 0.005254 acc: 85.0000%(12853/15000) \n",
            "\n",
            "Train Epoch: 157 \t Loss: 0.3401232063770294\n",
            "\n",
            "Evaluation - loss: 0.005233 acc: 85.0000%(12869/15000) \n",
            "\n",
            "Train Epoch: 158 \t Loss: 0.33509230613708496\n",
            "\n",
            "Evaluation - loss: 0.005232 acc: 85.0000%(12858/15000) \n",
            "\n",
            "Train Epoch: 159 \t Loss: 0.23140862584114075\n",
            "\n",
            "Evaluation - loss: 0.005245 acc: 85.0000%(12864/15000) \n",
            "\n",
            "Train Epoch: 160 \t Loss: 0.3031556308269501\n",
            "\n",
            "Evaluation - loss: 0.005242 acc: 85.0000%(12874/15000) \n",
            "\n",
            "Train Epoch: 161 \t Loss: 0.35286077857017517\n",
            "\n",
            "Evaluation - loss: 0.005231 acc: 85.0000%(12881/15000) \n",
            "\n",
            "Train Epoch: 162 \t Loss: 0.2677558362483978\n",
            "\n",
            "Evaluation - loss: 0.005210 acc: 85.0000%(12869/15000) \n",
            "\n",
            "Train Epoch: 163 \t Loss: 0.35213038325309753\n",
            "\n",
            "Evaluation - loss: 0.005210 acc: 85.0000%(12875/15000) \n",
            "\n",
            "Train Epoch: 164 \t Loss: 0.35149040818214417\n",
            "\n",
            "Evaluation - loss: 0.005217 acc: 85.0000%(12886/15000) \n",
            "\n",
            "Train Epoch: 165 \t Loss: 0.3180621564388275\n",
            "\n",
            "Evaluation - loss: 0.005194 acc: 85.0000%(12883/15000) \n",
            "\n",
            "Train Epoch: 166 \t Loss: 0.4337122142314911\n",
            "\n",
            "Evaluation - loss: 0.005166 acc: 85.0000%(12885/15000) \n",
            "\n",
            "Train Epoch: 167 \t Loss: 0.4001323878765106\n",
            "\n",
            "Evaluation - loss: 0.005139 acc: 86.0000%(12901/15000) \n",
            "\n",
            "Train Epoch: 168 \t Loss: 0.3806224465370178\n",
            "\n",
            "Evaluation - loss: 0.005139 acc: 85.0000%(12878/15000) \n",
            "\n",
            "Train Epoch: 169 \t Loss: 0.3638269305229187\n",
            "\n",
            "Evaluation - loss: 0.005192 acc: 85.0000%(12823/15000) \n",
            "\n",
            "Train Epoch: 170 \t Loss: 0.2586565911769867\n",
            "\n",
            "Evaluation - loss: 0.005228 acc: 85.0000%(12800/15000) \n",
            "\n",
            "Train Epoch: 171 \t Loss: 0.331367552280426\n",
            "\n",
            "Evaluation - loss: 0.005230 acc: 85.0000%(12790/15000) \n",
            "\n",
            "Train Epoch: 172 \t Loss: 0.3474697172641754\n",
            "\n",
            "Evaluation - loss: 0.005157 acc: 85.0000%(12840/15000) \n",
            "\n",
            "Train Epoch: 173 \t Loss: 0.32457268238067627\n",
            "\n",
            "Evaluation - loss: 0.005083 acc: 86.0000%(12908/15000) \n",
            "\n",
            "Train Epoch: 174 \t Loss: 0.35657650232315063\n",
            "\n",
            "Evaluation - loss: 0.005155 acc: 86.0000%(12912/15000) \n",
            "\n",
            "Train Epoch: 175 \t Loss: 0.3519049882888794\n",
            "\n",
            "Evaluation - loss: 0.005244 acc: 85.0000%(12866/15000) \n",
            "\n",
            "Train Epoch: 176 \t Loss: 0.41955700516700745\n",
            "\n",
            "Evaluation - loss: 0.005245 acc: 85.0000%(12861/15000) \n",
            "\n",
            "Train Epoch: 177 \t Loss: 0.33051055669784546\n",
            "\n",
            "Evaluation - loss: 0.005127 acc: 86.0000%(12935/15000) \n",
            "\n",
            "Train Epoch: 178 \t Loss: 0.29230451583862305\n",
            "\n",
            "Evaluation - loss: 0.005045 acc: 86.0000%(12912/15000) \n",
            "\n",
            "Train Epoch: 179 \t Loss: 0.355194091796875\n",
            "\n",
            "Evaluation - loss: 0.005044 acc: 86.0000%(12925/15000) \n",
            "\n",
            "Train Epoch: 180 \t Loss: 0.3001351058483124\n",
            "\n",
            "Evaluation - loss: 0.005033 acc: 86.0000%(12936/15000) \n",
            "\n",
            "Train Epoch: 181 \t Loss: 0.38114964962005615\n",
            "\n",
            "Evaluation - loss: 0.005034 acc: 86.0000%(12931/15000) \n",
            "\n",
            "Train Epoch: 182 \t Loss: 0.3600902259349823\n",
            "\n",
            "Evaluation - loss: 0.005028 acc: 86.0000%(12934/15000) \n",
            "\n",
            "Train Epoch: 183 \t Loss: 0.3584451377391815\n",
            "\n",
            "Evaluation - loss: 0.005020 acc: 86.0000%(12937/15000) \n",
            "\n",
            "Train Epoch: 184 \t Loss: 0.35000699758529663\n",
            "\n",
            "Evaluation - loss: 0.005036 acc: 86.0000%(12906/15000) \n",
            "\n",
            "Train Epoch: 185 \t Loss: 0.3128736913204193\n",
            "\n",
            "Evaluation - loss: 0.005055 acc: 85.0000%(12880/15000) \n",
            "\n",
            "Train Epoch: 186 \t Loss: 0.4928576350212097\n",
            "\n",
            "Evaluation - loss: 0.005011 acc: 86.0000%(12925/15000) \n",
            "\n",
            "Train Epoch: 187 \t Loss: 0.42107948660850525\n",
            "\n",
            "Evaluation - loss: 0.005044 acc: 86.0000%(12932/15000) \n",
            "\n",
            "Train Epoch: 188 \t Loss: 0.3462878167629242\n",
            "\n",
            "Evaluation - loss: 0.005215 acc: 85.0000%(12876/15000) \n",
            "\n",
            "Train Epoch: 189 \t Loss: 0.4460489749908447\n",
            "\n",
            "Evaluation - loss: 0.005384 acc: 85.0000%(12803/15000) \n",
            "\n",
            "Train Epoch: 190 \t Loss: 0.3632449209690094\n",
            "\n",
            "Evaluation - loss: 0.005428 acc: 85.0000%(12787/15000) \n",
            "\n",
            "Train Epoch: 191 \t Loss: 0.41757065057754517\n",
            "\n",
            "Evaluation - loss: 0.005354 acc: 85.0000%(12832/15000) \n",
            "\n",
            "Train Epoch: 192 \t Loss: 0.41551080346107483\n",
            "\n",
            "Evaluation - loss: 0.005188 acc: 86.0000%(12904/15000) \n",
            "\n",
            "Train Epoch: 193 \t Loss: 0.31610235571861267\n",
            "\n",
            "Evaluation - loss: 0.005038 acc: 86.0000%(12971/15000) \n",
            "\n",
            "Train Epoch: 194 \t Loss: 0.25418055057525635\n",
            "\n",
            "Evaluation - loss: 0.004977 acc: 86.0000%(12984/15000) \n",
            "\n",
            "Train Epoch: 195 \t Loss: 0.38615572452545166\n",
            "\n",
            "Evaluation - loss: 0.005005 acc: 86.0000%(12900/15000) \n",
            "\n",
            "Train Epoch: 196 \t Loss: 0.274658203125\n",
            "\n",
            "Evaluation - loss: 0.005082 acc: 85.0000%(12848/15000) \n",
            "\n",
            "Train Epoch: 197 \t Loss: 0.3918588161468506\n",
            "\n",
            "Evaluation - loss: 0.005176 acc: 85.0000%(12803/15000) \n",
            "\n",
            "Train Epoch: 198 \t Loss: 0.4369286596775055\n",
            "\n",
            "Evaluation - loss: 0.005147 acc: 85.0000%(12825/15000) \n",
            "\n",
            "Train Epoch: 199 \t Loss: 0.3466910421848297\n",
            "\n",
            "Evaluation - loss: 0.005073 acc: 85.0000%(12859/15000) \n",
            "\n",
            "Train Epoch: 200 \t Loss: 0.39818358421325684\n",
            "\n",
            "Evaluation - loss: 0.004978 acc: 86.0000%(12942/15000) \n",
            "\n",
            "Train Epoch: 201 \t Loss: 0.24011079967021942\n",
            "\n",
            "Evaluation - loss: 0.004955 acc: 86.0000%(13001/15000) \n",
            "\n",
            "Train Epoch: 202 \t Loss: 0.2905919551849365\n",
            "\n",
            "Evaluation - loss: 0.004989 acc: 86.0000%(13011/15000) \n",
            "\n",
            "Train Epoch: 203 \t Loss: 0.2397712618112564\n",
            "\n",
            "Evaluation - loss: 0.005023 acc: 86.0000%(12991/15000) \n",
            "\n",
            "Train Epoch: 204 \t Loss: 0.349555104970932\n",
            "\n",
            "Evaluation - loss: 0.005094 acc: 86.0000%(12991/15000) \n",
            "\n",
            "Train Epoch: 205 \t Loss: 0.30535727739334106\n",
            "\n",
            "Evaluation - loss: 0.005036 acc: 86.0000%(12997/15000) \n",
            "\n",
            "Train Epoch: 206 \t Loss: 0.475725919008255\n",
            "\n",
            "Evaluation - loss: 0.004960 acc: 86.0000%(13008/15000) \n",
            "\n",
            "Train Epoch: 207 \t Loss: 0.368309885263443\n",
            "\n",
            "Evaluation - loss: 0.004950 acc: 86.0000%(13014/15000) \n",
            "\n",
            "Train Epoch: 208 \t Loss: 0.3758369982242584\n",
            "\n",
            "Evaluation - loss: 0.004935 acc: 86.0000%(13021/15000) \n",
            "\n",
            "Train Epoch: 209 \t Loss: 0.5127665400505066\n",
            "\n",
            "Evaluation - loss: 0.004935 acc: 86.0000%(13022/15000) \n",
            "\n",
            "Train Epoch: 210 \t Loss: 0.31393367052078247\n",
            "\n",
            "Evaluation - loss: 0.004942 acc: 86.0000%(13026/15000) \n",
            "\n",
            "Train Epoch: 211 \t Loss: 0.34610652923583984\n",
            "\n",
            "Evaluation - loss: 0.004935 acc: 86.0000%(13024/15000) \n",
            "\n",
            "Train Epoch: 212 \t Loss: 0.21929609775543213\n",
            "\n",
            "Evaluation - loss: 0.004928 acc: 86.0000%(13029/15000) \n",
            "\n",
            "Train Epoch: 213 \t Loss: 0.36533188819885254\n",
            "\n",
            "Evaluation - loss: 0.004905 acc: 86.0000%(13029/15000) \n",
            "\n",
            "Train Epoch: 214 \t Loss: 0.3982086181640625\n",
            "\n",
            "Evaluation - loss: 0.004925 acc: 86.0000%(12992/15000) \n",
            "\n",
            "Train Epoch: 215 \t Loss: 0.3599581718444824\n",
            "\n",
            "Evaluation - loss: 0.004993 acc: 86.0000%(12940/15000) \n",
            "\n",
            "Train Epoch: 216 \t Loss: 0.40617257356643677\n",
            "\n",
            "Evaluation - loss: 0.005057 acc: 85.0000%(12893/15000) \n",
            "\n",
            "Train Epoch: 217 \t Loss: 0.49410152435302734\n",
            "\n",
            "Evaluation - loss: 0.005005 acc: 86.0000%(12930/15000) \n",
            "\n",
            "Train Epoch: 218 \t Loss: 0.257512629032135\n",
            "\n",
            "Evaluation - loss: 0.004951 acc: 86.0000%(12961/15000) \n",
            "\n",
            "Train Epoch: 219 \t Loss: 0.241383895277977\n",
            "\n",
            "Evaluation - loss: 0.004911 acc: 86.0000%(13010/15000) \n",
            "\n",
            "Train Epoch: 220 \t Loss: 0.2285650074481964\n",
            "\n",
            "Evaluation - loss: 0.004881 acc: 86.0000%(13027/15000) \n",
            "\n",
            "Train Epoch: 221 \t Loss: 0.2910846769809723\n",
            "\n",
            "Evaluation - loss: 0.004928 acc: 86.0000%(13026/15000) \n",
            "\n",
            "Train Epoch: 222 \t Loss: 0.36301326751708984\n",
            "\n",
            "Evaluation - loss: 0.004938 acc: 86.0000%(13025/15000) \n",
            "\n",
            "Train Epoch: 223 \t Loss: 0.21146461367607117\n",
            "\n",
            "Evaluation - loss: 0.004931 acc: 86.0000%(13032/15000) \n",
            "\n",
            "Train Epoch: 224 \t Loss: 0.22225652635097504\n",
            "\n",
            "Evaluation - loss: 0.004911 acc: 87.0000%(13053/15000) \n",
            "\n",
            "Train Epoch: 225 \t Loss: 0.42465654015541077\n",
            "\n",
            "Evaluation - loss: 0.004878 acc: 86.0000%(13047/15000) \n",
            "\n",
            "Train Epoch: 226 \t Loss: 0.3953649699687958\n",
            "\n",
            "Evaluation - loss: 0.004873 acc: 86.0000%(13032/15000) \n",
            "\n",
            "Train Epoch: 227 \t Loss: 0.24910801649093628\n",
            "\n",
            "Evaluation - loss: 0.004862 acc: 86.0000%(13030/15000) \n",
            "\n",
            "Train Epoch: 228 \t Loss: 0.44664937257766724\n",
            "\n",
            "Evaluation - loss: 0.004861 acc: 86.0000%(13016/15000) \n",
            "\n",
            "Train Epoch: 229 \t Loss: 0.2747832238674164\n",
            "\n",
            "Evaluation - loss: 0.004861 acc: 86.0000%(13022/15000) \n",
            "\n",
            "Train Epoch: 230 \t Loss: 0.36230313777923584\n",
            "\n",
            "Evaluation - loss: 0.004844 acc: 86.0000%(13025/15000) \n",
            "\n",
            "Train Epoch: 231 \t Loss: 0.3704334795475006\n",
            "\n",
            "Evaluation - loss: 0.004848 acc: 86.0000%(13040/15000) \n",
            "\n",
            "Train Epoch: 232 \t Loss: 0.3886701166629791\n",
            "\n",
            "Evaluation - loss: 0.004851 acc: 87.0000%(13057/15000) \n",
            "\n",
            "Train Epoch: 233 \t Loss: 0.5304526686668396\n",
            "\n",
            "Evaluation - loss: 0.004912 acc: 86.0000%(13017/15000) \n",
            "\n",
            "Train Epoch: 234 \t Loss: 0.29903772473335266\n",
            "\n",
            "Evaluation - loss: 0.004985 acc: 86.0000%(13003/15000) \n",
            "\n",
            "Train Epoch: 235 \t Loss: 0.33923327922821045\n",
            "\n",
            "Evaluation - loss: 0.004972 acc: 86.0000%(13010/15000) \n",
            "\n",
            "Train Epoch: 236 \t Loss: 0.4787714183330536\n",
            "\n",
            "Evaluation - loss: 0.004988 acc: 86.0000%(13007/15000) \n",
            "\n",
            "Train Epoch: 237 \t Loss: 0.2156478762626648\n",
            "\n",
            "Evaluation - loss: 0.004986 acc: 86.0000%(13007/15000) \n",
            "\n",
            "Train Epoch: 238 \t Loss: 0.3202395439147949\n",
            "\n",
            "Evaluation - loss: 0.004931 acc: 86.0000%(13013/15000) \n",
            "\n",
            "Train Epoch: 239 \t Loss: 0.36078429222106934\n",
            "\n",
            "Evaluation - loss: 0.004838 acc: 87.0000%(13056/15000) \n",
            "\n",
            "Train Epoch: 240 \t Loss: 0.40698662400245667\n",
            "\n",
            "Evaluation - loss: 0.004821 acc: 87.0000%(13052/15000) \n",
            "\n",
            "Train Epoch: 241 \t Loss: 0.2940523028373718\n",
            "\n",
            "Evaluation - loss: 0.004938 acc: 86.0000%(12944/15000) \n",
            "\n",
            "Train Epoch: 242 \t Loss: 0.3827223777770996\n",
            "\n",
            "Evaluation - loss: 0.005008 acc: 85.0000%(12897/15000) \n",
            "\n",
            "Train Epoch: 243 \t Loss: 0.4803018867969513\n",
            "\n",
            "Evaluation - loss: 0.004988 acc: 86.0000%(12914/15000) \n",
            "\n",
            "Train Epoch: 244 \t Loss: 0.4285435974597931\n",
            "\n",
            "Evaluation - loss: 0.004920 acc: 86.0000%(12965/15000) \n",
            "\n",
            "Train Epoch: 245 \t Loss: 0.32368430495262146\n",
            "\n",
            "Evaluation - loss: 0.004831 acc: 86.0000%(13024/15000) \n",
            "\n",
            "Train Epoch: 246 \t Loss: 0.32034924626350403\n",
            "\n",
            "Evaluation - loss: 0.004798 acc: 87.0000%(13061/15000) \n",
            "\n",
            "Train Epoch: 247 \t Loss: 0.30092549324035645\n",
            "\n",
            "Evaluation - loss: 0.004799 acc: 87.0000%(13085/15000) \n",
            "\n",
            "Train Epoch: 248 \t Loss: 0.38166067004203796\n",
            "\n",
            "Evaluation - loss: 0.004811 acc: 87.0000%(13078/15000) \n",
            "\n",
            "Train Epoch: 249 \t Loss: 0.31995174288749695\n",
            "\n",
            "Evaluation - loss: 0.004858 acc: 87.0000%(13060/15000) \n",
            "\n",
            "Train Epoch: 250 \t Loss: 0.3868980407714844\n",
            "\n",
            "Evaluation - loss: 0.004839 acc: 87.0000%(13070/15000) \n",
            "\n",
            "Train Epoch: 251 \t Loss: 0.3942449986934662\n",
            "\n",
            "Evaluation - loss: 0.004813 acc: 87.0000%(13089/15000) \n",
            "\n",
            "Train Epoch: 252 \t Loss: 0.27541351318359375\n",
            "\n",
            "Evaluation - loss: 0.004781 acc: 87.0000%(13075/15000) \n",
            "\n",
            "Train Epoch: 253 \t Loss: 0.20356325805187225\n",
            "\n",
            "Evaluation - loss: 0.004814 acc: 86.0000%(13045/15000) \n",
            "\n",
            "Train Epoch: 254 \t Loss: 0.3165484666824341\n",
            "\n",
            "Evaluation - loss: 0.004879 acc: 86.0000%(13008/15000) \n",
            "\n",
            "Train Epoch: 255 \t Loss: 0.38868454098701477\n",
            "\n",
            "Evaluation - loss: 0.004904 acc: 86.0000%(12990/15000) \n",
            "\n",
            "Train Epoch: 256 \t Loss: 0.22963427007198334\n",
            "\n",
            "Evaluation - loss: 0.004903 acc: 86.0000%(12986/15000) \n",
            "\n",
            "Train Epoch: 257 \t Loss: 0.317428857088089\n",
            "\n",
            "Evaluation - loss: 0.004851 acc: 86.0000%(13023/15000) \n",
            "\n",
            "Train Epoch: 258 \t Loss: 0.33564773201942444\n",
            "\n",
            "Evaluation - loss: 0.004798 acc: 87.0000%(13063/15000) \n",
            "\n",
            "Train Epoch: 259 \t Loss: 0.4267944097518921\n",
            "\n",
            "Evaluation - loss: 0.004767 acc: 87.0000%(13089/15000) \n",
            "\n",
            "Train Epoch: 260 \t Loss: 0.28330814838409424\n",
            "\n",
            "Evaluation - loss: 0.004779 acc: 87.0000%(13094/15000) \n",
            "\n",
            "Train Epoch: 261 \t Loss: 0.3489384055137634\n",
            "\n",
            "Evaluation - loss: 0.004804 acc: 87.0000%(13089/15000) \n",
            "\n",
            "Train Epoch: 262 \t Loss: 0.3410968482494354\n",
            "\n",
            "Evaluation - loss: 0.004807 acc: 87.0000%(13097/15000) \n",
            "\n",
            "Train Epoch: 263 \t Loss: 0.2422591745853424\n",
            "\n",
            "Evaluation - loss: 0.004776 acc: 87.0000%(13112/15000) \n",
            "\n",
            "Train Epoch: 264 \t Loss: 0.29160070419311523\n",
            "\n",
            "Evaluation - loss: 0.004771 acc: 87.0000%(13113/15000) \n",
            "\n",
            "Train Epoch: 265 \t Loss: 0.3523370623588562\n",
            "\n",
            "Evaluation - loss: 0.004762 acc: 87.0000%(13104/15000) \n",
            "\n",
            "Train Epoch: 266 \t Loss: 0.32422807812690735\n",
            "\n",
            "Evaluation - loss: 0.004746 acc: 87.0000%(13094/15000) \n",
            "\n",
            "Train Epoch: 267 \t Loss: 0.33217471837997437\n",
            "\n",
            "Evaluation - loss: 0.004787 acc: 87.0000%(13108/15000) \n",
            "\n",
            "Train Epoch: 268 \t Loss: 0.43931034207344055\n",
            "\n",
            "Evaluation - loss: 0.004800 acc: 87.0000%(13092/15000) \n",
            "\n",
            "Train Epoch: 269 \t Loss: 0.35413703322410583\n",
            "\n",
            "Evaluation - loss: 0.004798 acc: 87.0000%(13095/15000) \n",
            "\n",
            "Train Epoch: 270 \t Loss: 0.3200189769268036\n",
            "\n",
            "Evaluation - loss: 0.004782 acc: 87.0000%(13108/15000) \n",
            "\n",
            "Train Epoch: 271 \t Loss: 0.19636015594005585\n",
            "\n",
            "Evaluation - loss: 0.004777 acc: 87.0000%(13114/15000) \n",
            "\n",
            "Train Epoch: 272 \t Loss: 0.4629146456718445\n",
            "\n",
            "Evaluation - loss: 0.004770 acc: 87.0000%(13108/15000) \n",
            "\n",
            "Train Epoch: 273 \t Loss: 0.26672595739364624\n",
            "\n",
            "Evaluation - loss: 0.004767 acc: 87.0000%(13108/15000) \n",
            "\n",
            "Train Epoch: 274 \t Loss: 0.2961849570274353\n",
            "\n",
            "Evaluation - loss: 0.004770 acc: 87.0000%(13110/15000) \n",
            "\n",
            "Train Epoch: 275 \t Loss: 0.36790525913238525\n",
            "\n",
            "Evaluation - loss: 0.004760 acc: 87.0000%(13119/15000) \n",
            "\n",
            "Train Epoch: 276 \t Loss: 0.24795079231262207\n",
            "\n",
            "Evaluation - loss: 0.004749 acc: 87.0000%(13121/15000) \n",
            "\n",
            "Train Epoch: 277 \t Loss: 0.37456658482551575\n",
            "\n",
            "Evaluation - loss: 0.004741 acc: 87.0000%(13124/15000) \n",
            "\n",
            "Train Epoch: 278 \t Loss: 0.3496147394180298\n",
            "\n",
            "Evaluation - loss: 0.004736 acc: 87.0000%(13116/15000) \n",
            "\n",
            "Train Epoch: 279 \t Loss: 0.41477829217910767\n",
            "\n",
            "Evaluation - loss: 0.004726 acc: 87.0000%(13120/15000) \n",
            "\n",
            "Train Epoch: 280 \t Loss: 0.2107200026512146\n",
            "\n",
            "Evaluation - loss: 0.004729 acc: 87.0000%(13122/15000) \n",
            "\n",
            "Train Epoch: 281 \t Loss: 0.37803950905799866\n",
            "\n",
            "Evaluation - loss: 0.004710 acc: 87.0000%(13122/15000) \n",
            "\n",
            "Train Epoch: 282 \t Loss: 0.29724180698394775\n",
            "\n",
            "Evaluation - loss: 0.004720 acc: 87.0000%(13111/15000) \n",
            "\n",
            "Train Epoch: 283 \t Loss: 0.2311616688966751\n",
            "\n",
            "Evaluation - loss: 0.004736 acc: 87.0000%(13118/15000) \n",
            "\n",
            "Train Epoch: 284 \t Loss: 0.4590093493461609\n",
            "\n",
            "Evaluation - loss: 0.004726 acc: 87.0000%(13118/15000) \n",
            "\n",
            "Train Epoch: 285 \t Loss: 0.37812551856040955\n",
            "\n",
            "Evaluation - loss: 0.004692 acc: 87.0000%(13125/15000) \n",
            "\n",
            "Train Epoch: 286 \t Loss: 0.2541346848011017\n",
            "\n",
            "Evaluation - loss: 0.004691 acc: 87.0000%(13123/15000) \n",
            "\n",
            "Train Epoch: 287 \t Loss: 0.3351006805896759\n",
            "\n",
            "Evaluation - loss: 0.004696 acc: 87.0000%(13126/15000) \n",
            "\n",
            "Train Epoch: 288 \t Loss: 0.2929319441318512\n",
            "\n",
            "Evaluation - loss: 0.004698 acc: 87.0000%(13127/15000) \n",
            "\n",
            "Train Epoch: 289 \t Loss: 0.2433501034975052\n",
            "\n",
            "Evaluation - loss: 0.004717 acc: 87.0000%(13124/15000) \n",
            "\n",
            "Train Epoch: 290 \t Loss: 0.40007224678993225\n",
            "\n",
            "Evaluation - loss: 0.004690 acc: 87.0000%(13136/15000) \n",
            "\n",
            "Train Epoch: 291 \t Loss: 0.3886711895465851\n",
            "\n",
            "Evaluation - loss: 0.004668 acc: 87.0000%(13129/15000) \n",
            "\n",
            "Train Epoch: 292 \t Loss: 0.43234220147132874\n",
            "\n",
            "Evaluation - loss: 0.004662 acc: 87.0000%(13144/15000) \n",
            "\n",
            "Train Epoch: 293 \t Loss: 0.3646203577518463\n",
            "\n",
            "Evaluation - loss: 0.004668 acc: 87.0000%(13159/15000) \n",
            "\n",
            "Train Epoch: 294 \t Loss: 0.40839335322380066\n",
            "\n",
            "Evaluation - loss: 0.004668 acc: 87.0000%(13139/15000) \n",
            "\n",
            "Train Epoch: 295 \t Loss: 0.3169974684715271\n",
            "\n",
            "Evaluation - loss: 0.004656 acc: 87.0000%(13162/15000) \n",
            "\n",
            "Train Epoch: 296 \t Loss: 0.26562416553497314\n",
            "\n",
            "Evaluation - loss: 0.004652 acc: 87.0000%(13153/15000) \n",
            "\n",
            "Train Epoch: 297 \t Loss: 0.3644351065158844\n",
            "\n",
            "Evaluation - loss: 0.004647 acc: 87.0000%(13153/15000) \n",
            "\n",
            "Train Epoch: 298 \t Loss: 0.34278997778892517\n",
            "\n",
            "Evaluation - loss: 0.004657 acc: 87.0000%(13146/15000) \n",
            "\n",
            "Train Epoch: 299 \t Loss: 0.28297457098960876\n",
            "\n",
            "Evaluation - loss: 0.004696 acc: 87.0000%(13144/15000) \n",
            "\n",
            "Train Epoch: 300 \t Loss: 0.39203789830207825\n",
            "\n",
            "Evaluation - loss: 0.004669 acc: 87.0000%(13146/15000) \n",
            "\n",
            "Train Epoch: 301 \t Loss: 0.4151308834552765\n",
            "\n",
            "Evaluation - loss: 0.004665 acc: 87.0000%(13155/15000) \n",
            "\n",
            "Train Epoch: 302 \t Loss: 0.37644338607788086\n",
            "\n",
            "Evaluation - loss: 0.004626 acc: 87.0000%(13163/15000) \n",
            "\n",
            "Train Epoch: 303 \t Loss: 0.4578551948070526\n",
            "\n",
            "Evaluation - loss: 0.004622 acc: 87.0000%(13170/15000) \n",
            "\n",
            "Train Epoch: 304 \t Loss: 0.3083617091178894\n",
            "\n",
            "Evaluation - loss: 0.004621 acc: 87.0000%(13188/15000) \n",
            "\n",
            "Train Epoch: 305 \t Loss: 0.25492313504219055\n",
            "\n",
            "Evaluation - loss: 0.004644 acc: 87.0000%(13178/15000) \n",
            "\n",
            "Train Epoch: 306 \t Loss: 0.33656778931617737\n",
            "\n",
            "Evaluation - loss: 0.004691 acc: 87.0000%(13127/15000) \n",
            "\n",
            "Train Epoch: 307 \t Loss: 0.24478892982006073\n",
            "\n",
            "Evaluation - loss: 0.004714 acc: 87.0000%(13097/15000) \n",
            "\n",
            "Train Epoch: 308 \t Loss: 0.23959094285964966\n",
            "\n",
            "Evaluation - loss: 0.004667 acc: 87.0000%(13140/15000) \n",
            "\n",
            "Train Epoch: 309 \t Loss: 0.30883240699768066\n",
            "\n",
            "Evaluation - loss: 0.004655 acc: 87.0000%(13156/15000) \n",
            "\n",
            "Train Epoch: 310 \t Loss: 0.3710211217403412\n",
            "\n",
            "Evaluation - loss: 0.004610 acc: 87.0000%(13182/15000) \n",
            "\n",
            "Train Epoch: 311 \t Loss: 0.2826851010322571\n",
            "\n",
            "Evaluation - loss: 0.004590 acc: 87.0000%(13177/15000) \n",
            "\n",
            "Train Epoch: 312 \t Loss: 0.22439159452915192\n",
            "\n",
            "Evaluation - loss: 0.004597 acc: 87.0000%(13190/15000) \n",
            "\n",
            "Train Epoch: 313 \t Loss: 0.2823244631290436\n",
            "\n",
            "Evaluation - loss: 0.004605 acc: 87.0000%(13183/15000) \n",
            "\n",
            "Train Epoch: 314 \t Loss: 0.20972587168216705\n",
            "\n",
            "Evaluation - loss: 0.004614 acc: 87.0000%(13173/15000) \n",
            "\n",
            "Train Epoch: 315 \t Loss: 0.3023350238800049\n",
            "\n",
            "Evaluation - loss: 0.004592 acc: 87.0000%(13181/15000) \n",
            "\n",
            "Train Epoch: 316 \t Loss: 0.2948436141014099\n",
            "\n",
            "Evaluation - loss: 0.004585 acc: 87.0000%(13176/15000) \n",
            "\n",
            "Train Epoch: 317 \t Loss: 0.31281033158302307\n",
            "\n",
            "Evaluation - loss: 0.004565 acc: 87.0000%(13190/15000) \n",
            "\n",
            "Train Epoch: 318 \t Loss: 0.3004397451877594\n",
            "\n",
            "Evaluation - loss: 0.004557 acc: 87.0000%(13181/15000) \n",
            "\n",
            "Train Epoch: 319 \t Loss: 0.2571287751197815\n",
            "\n",
            "Evaluation - loss: 0.004567 acc: 87.0000%(13185/15000) \n",
            "\n",
            "Train Epoch: 320 \t Loss: 0.28404000401496887\n",
            "\n",
            "Evaluation - loss: 0.004571 acc: 87.0000%(13178/15000) \n",
            "\n",
            "Train Epoch: 321 \t Loss: 0.42447447776794434\n",
            "\n",
            "Evaluation - loss: 0.004567 acc: 87.0000%(13188/15000) \n",
            "\n",
            "Train Epoch: 322 \t Loss: 0.3341516852378845\n",
            "\n",
            "Evaluation - loss: 0.004546 acc: 87.0000%(13180/15000) \n",
            "\n",
            "Train Epoch: 323 \t Loss: 0.27964815497398376\n",
            "\n",
            "Evaluation - loss: 0.004548 acc: 87.0000%(13169/15000) \n",
            "\n",
            "Train Epoch: 324 \t Loss: 0.2553004026412964\n",
            "\n",
            "Evaluation - loss: 0.004539 acc: 87.0000%(13167/15000) \n",
            "\n",
            "Train Epoch: 325 \t Loss: 0.2563322186470032\n",
            "\n",
            "Evaluation - loss: 0.004541 acc: 87.0000%(13177/15000) \n",
            "\n",
            "Train Epoch: 326 \t Loss: 0.30088675022125244\n",
            "\n",
            "Evaluation - loss: 0.004539 acc: 87.0000%(13180/15000) \n",
            "\n",
            "Train Epoch: 327 \t Loss: 0.1841750293970108\n",
            "\n",
            "Evaluation - loss: 0.004539 acc: 87.0000%(13180/15000) \n",
            "\n",
            "Train Epoch: 328 \t Loss: 0.3425694704055786\n",
            "\n",
            "Evaluation - loss: 0.004575 acc: 87.0000%(13167/15000) \n",
            "\n",
            "Train Epoch: 329 \t Loss: 0.2848217189311981\n",
            "\n",
            "Evaluation - loss: 0.004634 acc: 87.0000%(13138/15000) \n",
            "\n",
            "Train Epoch: 330 \t Loss: 0.33106333017349243\n",
            "\n",
            "Evaluation - loss: 0.004640 acc: 87.0000%(13139/15000) \n",
            "\n",
            "Train Epoch: 331 \t Loss: 0.3247479498386383\n",
            "\n",
            "Evaluation - loss: 0.004667 acc: 87.0000%(13107/15000) \n",
            "\n",
            "Train Epoch: 332 \t Loss: 0.31063008308410645\n",
            "\n",
            "Evaluation - loss: 0.004651 acc: 87.0000%(13121/15000) \n",
            "\n",
            "Train Epoch: 333 \t Loss: 0.18323922157287598\n",
            "\n",
            "Evaluation - loss: 0.004615 acc: 87.0000%(13152/15000) \n",
            "\n",
            "Train Epoch: 334 \t Loss: 0.24489450454711914\n",
            "\n",
            "Evaluation - loss: 0.004569 acc: 87.0000%(13175/15000) \n",
            "\n",
            "Train Epoch: 335 \t Loss: 0.3932652473449707\n",
            "\n",
            "Evaluation - loss: 0.004531 acc: 87.0000%(13185/15000) \n",
            "\n",
            "Train Epoch: 336 \t Loss: 0.2941352128982544\n",
            "\n",
            "Evaluation - loss: 0.004512 acc: 87.0000%(13187/15000) \n",
            "\n",
            "Train Epoch: 337 \t Loss: 0.19437800347805023\n",
            "\n",
            "Evaluation - loss: 0.004544 acc: 87.0000%(13179/15000) \n",
            "\n",
            "Train Epoch: 338 \t Loss: 0.1516820639371872\n",
            "\n",
            "Evaluation - loss: 0.004627 acc: 87.0000%(13167/15000) \n",
            "\n",
            "Train Epoch: 339 \t Loss: 0.33473363518714905\n",
            "\n",
            "Evaluation - loss: 0.004809 acc: 87.0000%(13080/15000) \n",
            "\n",
            "Train Epoch: 340 \t Loss: 0.29820042848587036\n",
            "\n",
            "Evaluation - loss: 0.004967 acc: 86.0000%(13014/15000) \n",
            "\n",
            "Train Epoch: 341 \t Loss: 0.3199191987514496\n",
            "\n",
            "Evaluation - loss: 0.004891 acc: 86.0000%(13048/15000) \n",
            "\n",
            "Train Epoch: 342 \t Loss: 0.2999872863292694\n",
            "\n",
            "Evaluation - loss: 0.004830 acc: 87.0000%(13064/15000) \n",
            "\n",
            "Train Epoch: 343 \t Loss: 0.3028950095176697\n",
            "\n",
            "Evaluation - loss: 0.004695 acc: 87.0000%(13126/15000) \n",
            "\n",
            "Train Epoch: 344 \t Loss: 0.2052806317806244\n",
            "\n",
            "Evaluation - loss: 0.004565 acc: 87.0000%(13174/15000) \n",
            "\n",
            "Train Epoch: 345 \t Loss: 0.24500226974487305\n",
            "\n",
            "Evaluation - loss: 0.004501 acc: 87.0000%(13179/15000) \n",
            "\n",
            "Train Epoch: 346 \t Loss: 0.3155483901500702\n",
            "\n",
            "Evaluation - loss: 0.004541 acc: 87.0000%(13186/15000) \n",
            "\n",
            "Train Epoch: 347 \t Loss: 0.20966970920562744\n",
            "\n",
            "Evaluation - loss: 0.004634 acc: 87.0000%(13122/15000) \n",
            "\n",
            "Train Epoch: 348 \t Loss: 0.3820524215698242\n",
            "\n",
            "Evaluation - loss: 0.004653 acc: 87.0000%(13109/15000) \n",
            "\n",
            "Train Epoch: 349 \t Loss: 0.44092005491256714\n",
            "\n",
            "Evaluation - loss: 0.004681 acc: 87.0000%(13090/15000) \n",
            "\n",
            "Train Epoch: 350 \t Loss: 0.36517876386642456\n",
            "\n",
            "Evaluation - loss: 0.004655 acc: 87.0000%(13105/15000) \n",
            "\n",
            "Train Epoch: 351 \t Loss: 0.38553160429000854\n",
            "\n",
            "Evaluation - loss: 0.004602 acc: 87.0000%(13137/15000) \n",
            "\n",
            "Train Epoch: 352 \t Loss: 0.3704289197921753\n",
            "\n",
            "Evaluation - loss: 0.004555 acc: 87.0000%(13162/15000) \n",
            "\n",
            "Train Epoch: 353 \t Loss: 0.2517620027065277\n",
            "\n",
            "Evaluation - loss: 0.004515 acc: 88.0000%(13206/15000) \n",
            "\n",
            "Train Epoch: 354 \t Loss: 0.2982250154018402\n",
            "\n",
            "Evaluation - loss: 0.004480 acc: 87.0000%(13196/15000) \n",
            "\n",
            "Train Epoch: 355 \t Loss: 0.42896538972854614\n",
            "\n",
            "Evaluation - loss: 0.004478 acc: 88.0000%(13215/15000) \n",
            "\n",
            "Train Epoch: 356 \t Loss: 0.39552536606788635\n",
            "\n",
            "Evaluation - loss: 0.004491 acc: 87.0000%(13197/15000) \n",
            "\n",
            "Train Epoch: 357 \t Loss: 0.1565549671649933\n",
            "\n",
            "Evaluation - loss: 0.004507 acc: 88.0000%(13200/15000) \n",
            "\n",
            "Train Epoch: 358 \t Loss: 0.2018769234418869\n",
            "\n",
            "Evaluation - loss: 0.004518 acc: 88.0000%(13206/15000) \n",
            "\n",
            "Train Epoch: 359 \t Loss: 0.29094284772872925\n",
            "\n",
            "Evaluation - loss: 0.004493 acc: 88.0000%(13206/15000) \n",
            "\n",
            "Train Epoch: 360 \t Loss: 0.2373463213443756\n",
            "\n",
            "Evaluation - loss: 0.004469 acc: 88.0000%(13217/15000) \n",
            "\n",
            "Train Epoch: 361 \t Loss: 0.32835888862609863\n",
            "\n",
            "Evaluation - loss: 0.004461 acc: 88.0000%(13219/15000) \n",
            "\n",
            "Train Epoch: 362 \t Loss: 0.2672278881072998\n",
            "\n",
            "Evaluation - loss: 0.004473 acc: 88.0000%(13220/15000) \n",
            "\n",
            "Train Epoch: 363 \t Loss: 0.22410425543785095\n",
            "\n",
            "Evaluation - loss: 0.004474 acc: 88.0000%(13211/15000) \n",
            "\n",
            "Train Epoch: 364 \t Loss: 0.08946527540683746\n",
            "\n",
            "Evaluation - loss: 0.004488 acc: 88.0000%(13208/15000) \n",
            "\n",
            "Train Epoch: 365 \t Loss: 0.23146021366119385\n",
            "\n",
            "Evaluation - loss: 0.004488 acc: 88.0000%(13200/15000) \n",
            "\n",
            "Train Epoch: 366 \t Loss: 0.2235238254070282\n",
            "\n",
            "Evaluation - loss: 0.004456 acc: 88.0000%(13220/15000) \n",
            "\n",
            "Train Epoch: 367 \t Loss: 0.33503374457359314\n",
            "\n",
            "Evaluation - loss: 0.004444 acc: 88.0000%(13226/15000) \n",
            "\n",
            "Train Epoch: 368 \t Loss: 0.31531238555908203\n",
            "\n",
            "Evaluation - loss: 0.004445 acc: 88.0000%(13239/15000) \n",
            "\n",
            "Train Epoch: 369 \t Loss: 0.32585281133651733\n",
            "\n",
            "Evaluation - loss: 0.004522 acc: 88.0000%(13216/15000) \n",
            "\n",
            "Train Epoch: 370 \t Loss: 0.3174600899219513\n",
            "\n",
            "Evaluation - loss: 0.004577 acc: 87.0000%(13186/15000) \n",
            "\n",
            "Train Epoch: 371 \t Loss: 0.38269153237342834\n",
            "\n",
            "Evaluation - loss: 0.004557 acc: 87.0000%(13198/15000) \n",
            "\n",
            "Train Epoch: 372 \t Loss: 0.2821463644504547\n",
            "\n",
            "Evaluation - loss: 0.004528 acc: 88.0000%(13213/15000) \n",
            "\n",
            "Train Epoch: 373 \t Loss: 0.2816096842288971\n",
            "\n",
            "Evaluation - loss: 0.004435 acc: 88.0000%(13246/15000) \n",
            "\n",
            "Train Epoch: 374 \t Loss: 0.38332146406173706\n",
            "\n",
            "Evaluation - loss: 0.004407 acc: 88.0000%(13265/15000) \n",
            "\n",
            "Train Epoch: 375 \t Loss: 0.16529926657676697\n",
            "\n",
            "Evaluation - loss: 0.004402 acc: 88.0000%(13263/15000) \n",
            "\n",
            "Train Epoch: 376 \t Loss: 0.31765636801719666\n",
            "\n",
            "Evaluation - loss: 0.004393 acc: 88.0000%(13267/15000) \n",
            "\n",
            "Train Epoch: 377 \t Loss: 0.2908492684364319\n",
            "\n",
            "Evaluation - loss: 0.004384 acc: 88.0000%(13261/15000) \n",
            "\n",
            "Train Epoch: 378 \t Loss: 0.4354061484336853\n",
            "\n",
            "Evaluation - loss: 0.004387 acc: 88.0000%(13263/15000) \n",
            "\n",
            "Train Epoch: 379 \t Loss: 0.36363357305526733\n",
            "\n",
            "Evaluation - loss: 0.004390 acc: 88.0000%(13254/15000) \n",
            "\n",
            "Train Epoch: 380 \t Loss: 0.2485029399394989\n",
            "\n",
            "Evaluation - loss: 0.004375 acc: 88.0000%(13261/15000) \n",
            "\n",
            "Train Epoch: 381 \t Loss: 0.1939544528722763\n",
            "\n",
            "Evaluation - loss: 0.004381 acc: 88.0000%(13248/15000) \n",
            "\n",
            "Train Epoch: 382 \t Loss: 0.37973934412002563\n",
            "\n",
            "Evaluation - loss: 0.004425 acc: 88.0000%(13211/15000) \n",
            "\n",
            "Train Epoch: 383 \t Loss: 0.2832217514514923\n",
            "\n",
            "Evaluation - loss: 0.004512 acc: 87.0000%(13158/15000) \n",
            "\n",
            "Train Epoch: 384 \t Loss: 0.27792540192604065\n",
            "\n",
            "Evaluation - loss: 0.004509 acc: 87.0000%(13153/15000) \n",
            "\n",
            "Train Epoch: 385 \t Loss: 0.334269642829895\n",
            "\n",
            "Evaluation - loss: 0.004495 acc: 87.0000%(13159/15000) \n",
            "\n",
            "Train Epoch: 386 \t Loss: 0.34754255414009094\n",
            "\n",
            "Evaluation - loss: 0.004391 acc: 88.0000%(13222/15000) \n",
            "\n",
            "Train Epoch: 387 \t Loss: 0.14856387674808502\n",
            "\n",
            "Evaluation - loss: 0.004360 acc: 88.0000%(13277/15000) \n",
            "\n",
            "Train Epoch: 388 \t Loss: 0.2608555257320404\n",
            "\n",
            "Evaluation - loss: 0.004356 acc: 88.0000%(13276/15000) \n",
            "\n",
            "Train Epoch: 389 \t Loss: 0.21072156727313995\n",
            "\n",
            "Evaluation - loss: 0.004370 acc: 88.0000%(13283/15000) \n",
            "\n",
            "Train Epoch: 390 \t Loss: 0.24365459382534027\n",
            "\n",
            "Evaluation - loss: 0.004371 acc: 88.0000%(13276/15000) \n",
            "\n",
            "Train Epoch: 391 \t Loss: 0.33080145716667175\n",
            "\n",
            "Evaluation - loss: 0.004345 acc: 88.0000%(13282/15000) \n",
            "\n",
            "Train Epoch: 392 \t Loss: 0.2779861092567444\n",
            "\n",
            "Evaluation - loss: 0.004334 acc: 88.0000%(13286/15000) \n",
            "\n",
            "Train Epoch: 393 \t Loss: 0.41816943883895874\n",
            "\n",
            "Evaluation - loss: 0.004334 acc: 88.0000%(13295/15000) \n",
            "\n",
            "Train Epoch: 394 \t Loss: 0.37343546748161316\n",
            "\n",
            "Evaluation - loss: 0.004338 acc: 88.0000%(13230/15000) \n",
            "\n",
            "Train Epoch: 395 \t Loss: 0.2368704229593277\n",
            "\n",
            "Evaluation - loss: 0.004383 acc: 88.0000%(13234/15000) \n",
            "\n",
            "Train Epoch: 396 \t Loss: 0.3280656337738037\n",
            "\n",
            "Evaluation - loss: 0.004418 acc: 88.0000%(13212/15000) \n",
            "\n",
            "Train Epoch: 397 \t Loss: 0.3016512393951416\n",
            "\n",
            "Evaluation - loss: 0.004436 acc: 87.0000%(13184/15000) \n",
            "\n",
            "Train Epoch: 398 \t Loss: 0.32792264223098755\n",
            "\n",
            "Evaluation - loss: 0.004412 acc: 88.0000%(13206/15000) \n",
            "\n",
            "Train Epoch: 399 \t Loss: 0.21502362191677094\n",
            "\n",
            "Evaluation - loss: 0.004373 acc: 88.0000%(13239/15000) \n",
            "\n",
            "Train Epoch: 400 \t Loss: 0.23809531331062317\n",
            "\n",
            "Evaluation - loss: 0.004338 acc: 88.0000%(13244/15000) \n",
            "\n",
            "Train Epoch: 401 \t Loss: 0.30435001850128174\n",
            "\n",
            "Evaluation - loss: 0.004299 acc: 88.0000%(13277/15000) \n",
            "\n",
            "Train Epoch: 402 \t Loss: 0.28919509053230286\n",
            "\n",
            "Evaluation - loss: 0.004349 acc: 88.0000%(13304/15000) \n",
            "\n",
            "Train Epoch: 403 \t Loss: 0.25324493646621704\n",
            "\n",
            "Evaluation - loss: 0.004420 acc: 88.0000%(13269/15000) \n",
            "\n",
            "Train Epoch: 404 \t Loss: 0.33759552240371704\n",
            "\n",
            "Evaluation - loss: 0.004548 acc: 87.0000%(13181/15000) \n",
            "\n",
            "Train Epoch: 405 \t Loss: 0.17826144397258759\n",
            "\n",
            "Evaluation - loss: 0.004697 acc: 87.0000%(13123/15000) \n",
            "\n",
            "Train Epoch: 406 \t Loss: 0.36603039503097534\n",
            "\n",
            "Evaluation - loss: 0.004647 acc: 87.0000%(13142/15000) \n",
            "\n",
            "Train Epoch: 407 \t Loss: 0.22913949191570282\n",
            "\n",
            "Evaluation - loss: 0.004626 acc: 87.0000%(13149/15000) \n",
            "\n",
            "Train Epoch: 408 \t Loss: 0.4081379175186157\n",
            "\n",
            "Evaluation - loss: 0.004472 acc: 88.0000%(13218/15000) \n",
            "\n",
            "Train Epoch: 409 \t Loss: 0.27482107281684875\n",
            "\n",
            "Evaluation - loss: 0.004325 acc: 88.0000%(13308/15000) \n",
            "\n",
            "Train Epoch: 410 \t Loss: 0.32055625319480896\n",
            "\n",
            "Evaluation - loss: 0.004295 acc: 88.0000%(13280/15000) \n",
            "\n",
            "Train Epoch: 411 \t Loss: 0.19105710089206696\n",
            "\n",
            "Evaluation - loss: 0.004398 acc: 88.0000%(13221/15000) \n",
            "\n",
            "Train Epoch: 412 \t Loss: 0.25306499004364014\n",
            "\n",
            "Evaluation - loss: 0.004521 acc: 87.0000%(13136/15000) \n",
            "\n",
            "Train Epoch: 413 \t Loss: 0.3017514646053314\n",
            "\n",
            "Evaluation - loss: 0.004565 acc: 87.0000%(13117/15000) \n",
            "\n",
            "Train Epoch: 414 \t Loss: 0.211381196975708\n",
            "\n",
            "Evaluation - loss: 0.004561 acc: 87.0000%(13119/15000) \n",
            "\n",
            "Train Epoch: 415 \t Loss: 0.27594441175460815\n",
            "\n",
            "Evaluation - loss: 0.004488 acc: 87.0000%(13161/15000) \n",
            "\n",
            "Train Epoch: 416 \t Loss: 0.19205178320407867\n",
            "\n",
            "Evaluation - loss: 0.004393 acc: 88.0000%(13208/15000) \n",
            "\n",
            "Train Epoch: 417 \t Loss: 0.40724942088127136\n",
            "\n",
            "Evaluation - loss: 0.004281 acc: 88.0000%(13282/15000) \n",
            "\n",
            "Train Epoch: 418 \t Loss: 0.21515385806560516\n",
            "\n",
            "Evaluation - loss: 0.004281 acc: 88.0000%(13293/15000) \n",
            "\n",
            "Train Epoch: 419 \t Loss: 0.28980809450149536\n",
            "\n",
            "Evaluation - loss: 0.004320 acc: 88.0000%(13306/15000) \n",
            "\n",
            "Train Epoch: 420 \t Loss: 0.40409693121910095\n",
            "\n",
            "Evaluation - loss: 0.004340 acc: 88.0000%(13295/15000) \n",
            "\n",
            "Train Epoch: 421 \t Loss: 0.2791964113712311\n",
            "\n",
            "Evaluation - loss: 0.004289 acc: 88.0000%(13302/15000) \n",
            "\n",
            "Train Epoch: 422 \t Loss: 0.23624064028263092\n",
            "\n",
            "Evaluation - loss: 0.004268 acc: 88.0000%(13287/15000) \n",
            "\n",
            "Train Epoch: 423 \t Loss: 0.22326785326004028\n",
            "\n",
            "Evaluation - loss: 0.004261 acc: 88.0000%(13287/15000) \n",
            "\n",
            "Train Epoch: 424 \t Loss: 0.23919282853603363\n",
            "\n",
            "Evaluation - loss: 0.004274 acc: 88.0000%(13274/15000) \n",
            "\n",
            "Train Epoch: 425 \t Loss: 0.17769703269004822\n",
            "\n",
            "Evaluation - loss: 0.004256 acc: 88.0000%(13294/15000) \n",
            "\n",
            "Train Epoch: 426 \t Loss: 0.2998031675815582\n",
            "\n",
            "Evaluation - loss: 0.004260 acc: 88.0000%(13291/15000) \n",
            "\n",
            "Train Epoch: 427 \t Loss: 0.26720717549324036\n",
            "\n",
            "Evaluation - loss: 0.004257 acc: 88.0000%(13293/15000) \n",
            "\n",
            "Train Epoch: 428 \t Loss: 0.2653825879096985\n",
            "\n",
            "Evaluation - loss: 0.004267 acc: 88.0000%(13304/15000) \n",
            "\n",
            "Train Epoch: 429 \t Loss: 0.2257678359746933\n",
            "\n",
            "Evaluation - loss: 0.004264 acc: 88.0000%(13300/15000) \n",
            "\n",
            "Train Epoch: 430 \t Loss: 0.25470200181007385\n",
            "\n",
            "Evaluation - loss: 0.004258 acc: 88.0000%(13303/15000) \n",
            "\n",
            "Train Epoch: 431 \t Loss: 0.2535931169986725\n",
            "\n",
            "Evaluation - loss: 0.004253 acc: 88.0000%(13301/15000) \n",
            "\n",
            "Train Epoch: 432 \t Loss: 0.33845165371894836\n",
            "\n",
            "Evaluation - loss: 0.004235 acc: 88.0000%(13308/15000) \n",
            "\n",
            "Train Epoch: 433 \t Loss: 0.23720142245292664\n",
            "\n",
            "Evaluation - loss: 0.004235 acc: 88.0000%(13309/15000) \n",
            "\n",
            "Train Epoch: 434 \t Loss: 0.17025376856327057\n",
            "\n",
            "Evaluation - loss: 0.004244 acc: 88.0000%(13289/15000) \n",
            "\n",
            "Train Epoch: 435 \t Loss: 0.22810353338718414\n",
            "\n",
            "Evaluation - loss: 0.004258 acc: 88.0000%(13276/15000) \n",
            "\n",
            "Train Epoch: 436 \t Loss: 0.20661546289920807\n",
            "\n",
            "Evaluation - loss: 0.004264 acc: 88.0000%(13273/15000) \n",
            "\n",
            "Train Epoch: 437 \t Loss: 0.29329875111579895\n",
            "\n",
            "Evaluation - loss: 0.004266 acc: 88.0000%(13267/15000) \n",
            "\n",
            "Train Epoch: 438 \t Loss: 0.21299220621585846\n",
            "\n",
            "Evaluation - loss: 0.004259 acc: 88.0000%(13280/15000) \n",
            "\n",
            "Train Epoch: 439 \t Loss: 0.2576598823070526\n",
            "\n",
            "Evaluation - loss: 0.004244 acc: 88.0000%(13289/15000) \n",
            "\n",
            "Train Epoch: 440 \t Loss: 0.2501077353954315\n",
            "\n",
            "Evaluation - loss: 0.004231 acc: 88.0000%(13309/15000) \n",
            "\n",
            "Train Epoch: 441 \t Loss: 0.228763610124588\n",
            "\n",
            "Evaluation - loss: 0.004221 acc: 88.0000%(13315/15000) \n",
            "\n",
            "Train Epoch: 442 \t Loss: 0.27987709641456604\n",
            "\n",
            "Evaluation - loss: 0.004230 acc: 88.0000%(13324/15000) \n",
            "\n",
            "Train Epoch: 443 \t Loss: 0.28694266080856323\n",
            "\n",
            "Evaluation - loss: 0.004256 acc: 88.0000%(13314/15000) \n",
            "\n",
            "Train Epoch: 444 \t Loss: 0.2605552077293396\n",
            "\n",
            "Evaluation - loss: 0.004286 acc: 88.0000%(13291/15000) \n",
            "\n",
            "Train Epoch: 445 \t Loss: 0.2580847144126892\n",
            "\n",
            "Evaluation - loss: 0.004316 acc: 88.0000%(13275/15000) \n",
            "\n",
            "Train Epoch: 446 \t Loss: 0.29266613721847534\n",
            "\n",
            "Evaluation - loss: 0.004332 acc: 88.0000%(13275/15000) \n",
            "\n",
            "Train Epoch: 447 \t Loss: 0.37408894300460815\n",
            "\n",
            "Evaluation - loss: 0.004258 acc: 88.0000%(13307/15000) \n",
            "\n",
            "Train Epoch: 448 \t Loss: 0.24882476031780243\n",
            "\n",
            "Evaluation - loss: 0.004236 acc: 88.0000%(13337/15000) \n",
            "\n",
            "Train Epoch: 449 \t Loss: 0.28844672441482544\n",
            "\n",
            "Evaluation - loss: 0.004199 acc: 88.0000%(13325/15000) \n",
            "\n",
            "Train Epoch: 450 \t Loss: 0.20858481526374817\n",
            "\n",
            "Evaluation - loss: 0.004202 acc: 88.0000%(13315/15000) \n",
            "\n",
            "Train Epoch: 451 \t Loss: 0.21717949211597443\n",
            "\n",
            "Evaluation - loss: 0.004222 acc: 88.0000%(13302/15000) \n",
            "\n",
            "Train Epoch: 452 \t Loss: 0.30301329493522644\n",
            "\n",
            "Evaluation - loss: 0.004216 acc: 88.0000%(13295/15000) \n",
            "\n",
            "Train Epoch: 453 \t Loss: 0.25433021783828735\n",
            "\n",
            "Evaluation - loss: 0.004213 acc: 88.0000%(13305/15000) \n",
            "\n",
            "Train Epoch: 454 \t Loss: 0.2449476718902588\n",
            "\n",
            "Evaluation - loss: 0.004212 acc: 88.0000%(13326/15000) \n",
            "\n",
            "Train Epoch: 455 \t Loss: 0.26703745126724243\n",
            "\n",
            "Evaluation - loss: 0.004216 acc: 88.0000%(13333/15000) \n",
            "\n",
            "Train Epoch: 456 \t Loss: 0.2050246149301529\n",
            "\n",
            "Evaluation - loss: 0.004252 acc: 88.0000%(13323/15000) \n",
            "\n",
            "Train Epoch: 457 \t Loss: 0.24798902869224548\n",
            "\n",
            "Evaluation - loss: 0.004277 acc: 88.0000%(13313/15000) \n",
            "\n",
            "Train Epoch: 458 \t Loss: 0.3628818690776825\n",
            "\n",
            "Evaluation - loss: 0.004277 acc: 88.0000%(13321/15000) \n",
            "\n",
            "Train Epoch: 459 \t Loss: 0.34717312455177307\n",
            "\n",
            "Evaluation - loss: 0.004248 acc: 88.0000%(13333/15000) \n",
            "\n",
            "Train Epoch: 460 \t Loss: 0.23623506724834442\n",
            "\n",
            "Evaluation - loss: 0.004207 acc: 88.0000%(13322/15000) \n",
            "\n",
            "Train Epoch: 461 \t Loss: 0.2343304455280304\n",
            "\n",
            "Evaluation - loss: 0.004212 acc: 88.0000%(13311/15000) \n",
            "\n",
            "Train Epoch: 462 \t Loss: 0.2173413336277008\n",
            "\n",
            "Evaluation - loss: 0.004210 acc: 88.0000%(13298/15000) \n",
            "\n",
            "Train Epoch: 463 \t Loss: 0.33148133754730225\n",
            "\n",
            "Evaluation - loss: 0.004255 acc: 88.0000%(13278/15000) \n",
            "\n",
            "Train Epoch: 464 \t Loss: 0.19930894672870636\n",
            "\n",
            "Evaluation - loss: 0.004310 acc: 88.0000%(13231/15000) \n",
            "\n",
            "Train Epoch: 465 \t Loss: 0.22361385822296143\n",
            "\n",
            "Evaluation - loss: 0.004363 acc: 88.0000%(13201/15000) \n",
            "\n",
            "Train Epoch: 466 \t Loss: 0.21636077761650085\n",
            "\n",
            "Evaluation - loss: 0.004452 acc: 87.0000%(13177/15000) \n",
            "\n",
            "Train Epoch: 467 \t Loss: 0.2561097741127014\n",
            "\n",
            "Evaluation - loss: 0.004428 acc: 87.0000%(13175/15000) \n",
            "\n",
            "Train Epoch: 468 \t Loss: 0.3407181203365326\n",
            "\n",
            "Evaluation - loss: 0.004379 acc: 87.0000%(13199/15000) \n",
            "\n",
            "Train Epoch: 469 \t Loss: 0.2881482243537903\n",
            "\n",
            "Evaluation - loss: 0.004312 acc: 88.0000%(13238/15000) \n",
            "\n",
            "Train Epoch: 470 \t Loss: 0.33698007464408875\n",
            "\n",
            "Evaluation - loss: 0.004228 acc: 88.0000%(13287/15000) \n",
            "\n",
            "Train Epoch: 471 \t Loss: 0.4291895627975464\n",
            "\n",
            "Evaluation - loss: 0.004187 acc: 88.0000%(13304/15000) \n",
            "\n",
            "Train Epoch: 472 \t Loss: 0.32430487871170044\n",
            "\n",
            "Evaluation - loss: 0.004190 acc: 88.0000%(13346/15000) \n",
            "\n",
            "Train Epoch: 473 \t Loss: 0.27563291788101196\n",
            "\n",
            "Evaluation - loss: 0.004200 acc: 89.0000%(13361/15000) \n",
            "\n",
            "Train Epoch: 474 \t Loss: 0.24862314760684967\n",
            "\n",
            "Evaluation - loss: 0.004198 acc: 89.0000%(13363/15000) \n",
            "\n",
            "Train Epoch: 475 \t Loss: 0.24628150463104248\n",
            "\n",
            "Evaluation - loss: 0.004206 acc: 89.0000%(13359/15000) \n",
            "\n",
            "Train Epoch: 476 \t Loss: 0.1792427897453308\n",
            "\n",
            "Evaluation - loss: 0.004188 acc: 89.0000%(13354/15000) \n",
            "\n",
            "Train Epoch: 477 \t Loss: 0.1737809181213379\n",
            "\n",
            "Evaluation - loss: 0.004190 acc: 88.0000%(13331/15000) \n",
            "\n",
            "Train Epoch: 478 \t Loss: 0.29834505915641785\n",
            "\n",
            "Evaluation - loss: 0.004185 acc: 88.0000%(13309/15000) \n",
            "\n",
            "Train Epoch: 479 \t Loss: 0.18099433183670044\n",
            "\n",
            "Evaluation - loss: 0.004195 acc: 88.0000%(13299/15000) \n",
            "\n",
            "Train Epoch: 480 \t Loss: 0.33575594425201416\n",
            "\n",
            "Evaluation - loss: 0.004195 acc: 88.0000%(13299/15000) \n",
            "\n",
            "Train Epoch: 481 \t Loss: 0.28420230746269226\n",
            "\n",
            "Evaluation - loss: 0.004187 acc: 88.0000%(13307/15000) \n",
            "\n",
            "Train Epoch: 482 \t Loss: 0.21467754244804382\n",
            "\n",
            "Evaluation - loss: 0.004181 acc: 88.0000%(13321/15000) \n",
            "\n",
            "Train Epoch: 483 \t Loss: 0.25124549865722656\n",
            "\n",
            "Evaluation - loss: 0.004194 acc: 89.0000%(13351/15000) \n",
            "\n",
            "Train Epoch: 484 \t Loss: 0.20530644059181213\n",
            "\n",
            "Evaluation - loss: 0.004180 acc: 88.0000%(13342/15000) \n",
            "\n",
            "Train Epoch: 485 \t Loss: 0.14466792345046997\n",
            "\n",
            "Evaluation - loss: 0.004192 acc: 88.0000%(13322/15000) \n",
            "\n",
            "Train Epoch: 486 \t Loss: 0.28608885407447815\n",
            "\n",
            "Evaluation - loss: 0.004183 acc: 88.0000%(13309/15000) \n",
            "\n",
            "Train Epoch: 487 \t Loss: 0.1967642605304718\n",
            "\n",
            "Evaluation - loss: 0.004179 acc: 88.0000%(13313/15000) \n",
            "\n",
            "Train Epoch: 488 \t Loss: 0.15552479028701782\n",
            "\n",
            "Evaluation - loss: 0.004179 acc: 88.0000%(13323/15000) \n",
            "\n",
            "Train Epoch: 489 \t Loss: 0.22518956661224365\n",
            "\n",
            "Evaluation - loss: 0.004177 acc: 88.0000%(13338/15000) \n",
            "\n",
            "Train Epoch: 490 \t Loss: 0.2828913629055023\n",
            "\n",
            "Evaluation - loss: 0.004172 acc: 88.0000%(13339/15000) \n",
            "\n",
            "Train Epoch: 491 \t Loss: 0.1898278295993805\n",
            "\n",
            "Evaluation - loss: 0.004173 acc: 88.0000%(13336/15000) \n",
            "\n",
            "Train Epoch: 492 \t Loss: 0.18444901704788208\n",
            "\n",
            "Evaluation - loss: 0.004178 acc: 88.0000%(13334/15000) \n",
            "\n",
            "Train Epoch: 493 \t Loss: 0.18548524379730225\n",
            "\n",
            "Evaluation - loss: 0.004196 acc: 89.0000%(13353/15000) \n",
            "\n",
            "Train Epoch: 494 \t Loss: 0.24333059787750244\n",
            "\n",
            "Evaluation - loss: 0.004179 acc: 89.0000%(13354/15000) \n",
            "\n",
            "Train Epoch: 495 \t Loss: 0.22499465942382812\n",
            "\n",
            "Evaluation - loss: 0.004185 acc: 89.0000%(13354/15000) \n",
            "\n",
            "Train Epoch: 496 \t Loss: 0.24780689179897308\n",
            "\n",
            "Evaluation - loss: 0.004180 acc: 89.0000%(13353/15000) \n",
            "\n",
            "Train Epoch: 497 \t Loss: 0.10835627466440201\n",
            "\n",
            "Evaluation - loss: 0.004166 acc: 89.0000%(13352/15000) \n",
            "\n",
            "Train Epoch: 498 \t Loss: 0.35187608003616333\n",
            "\n",
            "Evaluation - loss: 0.004162 acc: 88.0000%(13348/15000) \n",
            "\n",
            "Train Epoch: 499 \t Loss: 0.19461221992969513\n",
            "\n",
            "Evaluation - loss: 0.004172 acc: 88.0000%(13316/15000) \n",
            "\n",
            "Train Epoch: 500 \t Loss: 0.32684385776519775\n",
            "\n",
            "Evaluation - loss: 0.004187 acc: 88.0000%(13320/15000) \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-2c_6zMdwfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}